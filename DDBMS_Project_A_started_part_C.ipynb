{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDBMS_Project_A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHjqpaT0rIod",
        "outputId": "b53e74aa-570d-4618-d632-1ea6e8c6d782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 36.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=0c9f303e907b1a11bca73ed885b00737073073eddad402178856b067ddad6223\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Current file = queries.csv\n",
        "\n",
        "# Transform the file to tsv format\n",
        "import csv\n",
        "\n",
        "with open('queries.csv','r') as csvin, open('queries.tsv', 'w') as tsvout:\n",
        "    csvin = csv.reader(csvin)\n",
        "    tsvout = csv.writer(tsvout, delimiter='\\t')\n",
        "    for row in csvin:\n",
        "        tsvout.writerow(row)\n",
        "\n",
        "from pyspark.sql import SparkSession,Row, Column\n",
        "import pyspark.sql.functions as F\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "queries_file = 'queries.tsv'\n",
        "df = spark.read.csv(queries_file, header='True', inferSchema='True', sep='\\t')\n",
        "\n",
        "\n",
        "column_names = [\"genres\", \"lang\", \"actors\", \"director\", \"cities\", \"country\", \n",
        "                \"from_realese_date\", \"production_company\"]\n",
        "# For all the above columns\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"'[]\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Queries table:\")\n",
        "df.show()\n",
        "queries_df = df\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Current file: credits.csv\n",
        "import re\n",
        "credits_file = 'credits.csv'\n",
        "df = spark.read.csv(credits_file, header='True', inferSchema='True')\n",
        "\n",
        "# Load the data (given code)\n",
        "credits = spark.read.format(\"csv\")\\\n",
        ".option(\"delimiter\", \"\\t\")\\\n",
        ".option(\"header\",\"true\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".load(\"credits.csv\")\n",
        "prog = re.compile('\\\\[(.*?)\\\\]')\n",
        "second_match = F.udf(lambda x: prog.findall(x)[1])\n",
        "id_extract = F.udf(lambda x: x.split(\",\")[-1])\n",
        "credits = credits\\\n",
        ".withColumn(\"id\", id_extract(\"cast,crew,id\"))\\\n",
        ".withColumn(\"cast\", F.regexp_extract(F.col(\"cast,crew,id\"), '\\\\[(.*?)\\\\]', 0\n",
        "))\\\n",
        ".withColumn(\"crew\", F.concat(F.lit(\"[\"),second_match(\"cast,crew,id\"), F.lit(\n",
        "\"]\")))\\\n",
        ".select(\"cast\", \"crew\", \"id\")\n",
        "\n",
        "df = credits\n",
        "column_names = [\"cast\", \"crew\"]\n",
        "# For all the above columns\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "# For cast column - udf for extracting actors' names only from cast json string\n",
        "actors_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 8 == 5])\n",
        "df = df.withColumn('actors', actors_udf(F.col(\"cast\")))\\\n",
        "  .drop(\"cast\")\n",
        "\n",
        "# For crew column - udf for extracting directors' names only from crew json string\n",
        "directors_udf = F.udf(lambda arr: [arr[i+1][7:] for i in range(len(arr))\n",
        " if arr[i] == \" job: Director\"])\n",
        "df = df.withColumn('directors', directors_udf(F.col(\"crew\")))\\\n",
        "  .drop(\"crew\")\n",
        "\n",
        "# Converting arrays strings to arrays of strings\n",
        "column_names = [\"actors\", \"directors\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Credits table:\")\n",
        "df.show()\n",
        "credits_df = df\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Current file: movies.csv\n",
        "movies_file = 'movies.csv'\n",
        "df = spark.read.csv(movies_file, header='True', inferSchema='True')\n",
        "\n",
        "# Doing the same process for all columns\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\", \"cities\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "# Finished working on cities column, and seperating production_companies\n",
        "# because it has different structure\n",
        "column_names = [\"genres\", \"production_countries\", \"spoken_languages\"]\n",
        "\n",
        "# For each column - udf for extracting names only from json string\n",
        "name_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 2 == 1])\n",
        "for c in column_names:\n",
        "  c_1 = c + \"1\"\n",
        "  df = df.withColumn(c_1, name_udf(F.col(c)))\\\n",
        "    .drop(c)\n",
        "prod_udf = F.udf(lambda arr: [arr[i][6:] for i in range(len(arr)) if i % 2 == 0])\n",
        "df = df.withColumn(\"production_companies1\", prod_udf(F.col(\"production_companies\")))\\\n",
        "  .drop(\"production_companies\")\n",
        "\n",
        "# Renameing columns names\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\"]\n",
        "for name in column_names:\n",
        "  current_name = name + \"1\"\n",
        "  df = df.withColumnRenamed(current_name,name)\n",
        "\n",
        "print(\"Movies table:\")\n",
        "df.show()\n",
        "movies_df = df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBObp4SAYX9N",
        "outputId": "c3243bce-82af-42d7-95b2-75c6672ef6ac"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries table:\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|user_id|              genres|                lang|              actors|            director|              cities|             country|from_realese_date|  production_company|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|    981| [Western,  Mystery]|  [English,  Srpski]|                  []|      [Nae Caranfil]|  [Haifa,  Tiberias]|                  []|           [2012]|[Katakuri-ke no K...|\n",
            "|   3775|  [Action,  Western]|           [English]|                  []|                  []|          [Tel Aviv]|                  []|           [2013]|[Clavius Base,  T...|\n",
            "|   4095|             [Crime]|[English,  עִבְרִית]|[Kenneth Alton,  ...|                  []|         [Jerusalem]| [Belgium,  Moldova]|           [1995]|[Peter Carsten Pr...|\n",
            "|   3363|[Animation,  West...|           [English]|                  []|      [Philip Dunne]|             [Haifa]|           [Croatia]|           [2014]|[Centrul de Produ...|\n",
            "|   8982|[Action,  Documen...|           [English]|                  []|                  []|[Tel Aviv,  Jerus...|                  []|           [2018]|[Vortex Words Pic...|\n",
            "|   7603|          [TV Movie]|           [English]|[Tom Hanks,  Stua...|                  []|         [Jerusalem]|  [Jamaica,  Israel]|           [1999]|   [Northern Lights]|\n",
            "|   3112|[Fantasy,  Advent...|           [English]|                  []|                  []|             [Eilat]|[Guatemala,  Kyrg...|           [1996]|[Warner Bros,  Pi...|\n",
            "|   7217|[Drama,  Animatio...|[English,  עִבְרִית]|                  []|                  []|         [Jerusalem]|    [Qatar,  Israel]|           [1999]|             [Chill]|\n",
            "|   9716|   [Crime,  Romance]|           [English]|                  []|                  []|             [Eilat]|[Switzerland,  Mo...|           [2006]|[Monogram Picture...|\n",
            "|   4832|[Drama,  Animatio...|           [English]|                  []|    [Michael Tiddes]|             [Haifa]|                  []|           [2012]|[Joel Productions...|\n",
            "|   8260|            [Family]|           [English]|[\"\"\"Terry OQuinn\"...|                  []|          [Tiberias]| [Namibia,  Morocco]|           [1998]|[TROS Bridge Rights]|\n",
            "|   2772|   [Action,  Family]|           [English]|[Harry Carey,  Jr...|                  []|          [Tel Aviv]|                  []|           [2017]|[MGM-Pathé Commun...|\n",
            "|   8971|[Adventure,  Scie...|           [English]|                  []|                  []|             [Eilat]|  [Congo,  Ethiopia]|           [2004]|[Walt Disney Pict...|\n",
            "|  10496| [Drama,  Animation]|           [English]|[Osamu Hosoi,  Eu...|[Julia Sweeney,  ...|             [Haifa]|                  []|           [2016]|[RTV Slovenija,  ...|\n",
            "|   9658|[Drama,  Adventur...|           [English]|      [Otto Klopsch]|       [So Yong Kim]|             [Haifa]|                  []|           [2018]|[Rational Packagi...|\n",
            "|  10114|[Horror,  Adventure]| [English,  ภาษาไทย]|                  []|                  []|             [Eilat]|[Netherlands,  Ka...|           [2016]|[Walt Disney Pict...|\n",
            "|   2727|[Drama,  Adventur...|   [English,  ?????]|[Bernadette Leonard]|[Philippe Le Guay...|             [Haifa]|                  []|           [2018]|[HE-Filmproduktio...|\n",
            "|   1889|[Drama,  Horror, ...|           [English]|    [Hassan Majooni]|                  []|             [Haifa]|                  []|           [2016]|[\"\"\"Thats Nice Fi...|\n",
            "|   8235|    [Drama,  Action]|           [English]|        [Gil Herman]|      [Mariano Cohn]|             [Haifa]|                  []|           [2012]|[\"\"\"Centre Nation...|\n",
            "|   6345|[Animation,  Adve...|           [English]|                  []|                  []|             [Eilat]|[South Korea,  Mo...|           [2012]|[Pixar Animation ...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Credits table:\n",
            "+-----+--------------------+--------------------+\n",
            "|   id|              actors|           directors|\n",
            "+-----+--------------------+--------------------+\n",
            "|  862|[Tom Hanks,  Tim ...|     [John Lasseter]|\n",
            "| 8844|[Robin Williams, ...|      [Joe Johnston]|\n",
            "|15602|[Walter Matthau, ...|     [Howard Deutch]|\n",
            "|31357|[Whitney Houston,...|   [Forest Whitaker]|\n",
            "|11862|[Steve Martin,  D...|     [Charles Shyer]|\n",
            "|  949|[Al Pacino,  Robe...|      [Michael Mann]|\n",
            "|11860|[Harrison Ford,  ...|    [Sydney Pollack]|\n",
            "|45325|[Jonathan Taylor ...|      [Peter Hewitt]|\n",
            "| 9091|[Jean-Claude Van ...|       [Peter Hyams]|\n",
            "|  710|[Pierce Brosnan, ...|   [Martin Campbell]|\n",
            "| 9087|[Michael Douglas,...|        [Rob Reiner]|\n",
            "|12110|[Leslie Nielsen, ...|        [Mel Brooks]|\n",
            "|21032|[Kevin Bacon,  Bo...|       [Simon Wells]|\n",
            "|10858|[Anthony Hopkins,...|      [Oliver Stone]|\n",
            "| 1408|[Geena Davis,  Ma...|      [Renny Harlin]|\n",
            "|  524|[Robert De Niro, ...|   [Martin Scorsese]|\n",
            "| 4584|[Kate Winslet,  E...|           [Ang Lee]|\n",
            "|    5|[Tim Roth,  Anton...|[Allison Anders, ...|\n",
            "| 9273|[Jim Carrey,  Ian...|    [Steve Oedekerk]|\n",
            "|11517|[Wesley Snipes,  ...|      [Joseph Ruben]|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Movies table:\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|movie_id|            overview|        release_date|             revenue|             tagline|               title|              cities|              genres|production_countries|    spoken_languages|production_companies|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     862|Led by Woody, And...|          30/10/1995|           373554033|                null|           Toy Story|[Eilat,  Tel Aviv...|[Animation, Comed...|[United States of...|           [English]|[Pixar Animation ...|\n",
            "|    8844|When siblings Jud...|          15/12/1995|           262797249|Roll the dice and...|             Jumanji|[Jerusalem,  Tibe...|[Adventure, Fanta...|[United States of...|[English, FranÃ§ais]|[TriStar Pictures...|\n",
            "|   15602|A family wedding ...|          22/12/1995|                   0|Still Yelling. St...|    Grumpier Old Men|[Eilat,  Haifa,  ...|   [Romance, Comedy]|[United States of...|           [English]|[Warner Bros.,  L...|\n",
            "|   31357|\"Cheated on, mist...| determined to fi...|[{'name': 'Twenti...|          22/12/1995|            81452156|[iso_639_1: en,  ...|[Comedy, Drama, R...|                  []|[United States of...|                 [e]|\n",
            "|   11862|Just when George ...|          10/02/1995|            76578911|Just When His Wor...|Father of the Bri...|[Haifa,  Jerusale...|            [Comedy]|[United States of...|           [English]|[Sandollar Produc...|\n",
            "|     949|Obsessive master ...|          15/12/1995|           187436818|A Los Angeles Cri...|                Heat|[Tiberias,  Jerus...|[Action, Crime, D...|[United States of...| [English, EspaÃ±ol]|[Regency Enterpri...|\n",
            "|   11860|An ugly duckling ...|          15/12/1995|                   0|You are cordially...|             Sabrina|[Eilat,  Jerusale...|   [Comedy, Romance]|[Germany, United ...|[FranÃ§ais, English]|[Paramount Pictur...|\n",
            "|   45325|A mischievous you...|          22/12/1995|                   0|The Original Bad ...|        Tom and Huck|[Haifa,  Jerusale...|[Action, Adventur...|[United States of...|  [English, Deutsch]|[Walt Disney Pict...|\n",
            "|    9091|International act...|          22/12/1995|            64350171|Terror goes into ...|        Sudden Death|[Tiberias,  Haifa...|[Action, Adventur...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|     710|James Bond must u...|          16/11/1995|           352194034|No limits. No fea...|           GoldenEye|[Eilat,  Tiberias...|[Adventure, Actio...|[United Kingdom, ...|[English, PÑÑÑ...|[United Artists, ...|\n",
            "|    9087|Widowed U.S. pres...|          17/11/1995|           107879496|Why can't the mos...|The American Pres...|[Haifa,  Tel Aviv...|[Comedy, Drama, R...|[United States of...|           [English]|[Columbia Picture...|\n",
            "|   12110|When a lawyer sho...|          22/12/1995|                   0|                null|Dracula: Dead and...|[Tiberias,  Jerus...|    [Comedy, Horror]|[France, United S...|  [English, Deutsch]|[Columbia Picture...|\n",
            "|   21032|An outcast half-w...|          22/12/1995|            11348324|Part Dog. Part Wo...|               Balto|[Jerusalem,  Haif...|[Family, Animatio...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|   10858|An all-star cast ...|          22/12/1995|            13681765|Triumphant in Vic...|               Nixon|[Eilat,  Haifa,  ...|    [History, Drama]|[United States of...|           [English]|[Hollywood Pictur...|\n",
            "|    1408|Morgan Adams and ...|          22/12/1995|            10017322|The Course Has Be...|    Cutthroat Island|[Tiberias,  Eilat...| [Action, Adventure]|[France, Germany,...|    [English, Latin]|[Le Studio Canal+...|\n",
            "|     524|The life of the g...|          22/11/1995|           116112375|No one stays at t...|              Casino|[Tel Aviv,  Eilat...|      [Drama, Crime]|[France, United S...|           [English]|[Universal Pictur...|\n",
            "|    4584|Rich Mr. Dashwood...|          13/12/1995|           135000000|Lose your heart a...|Sense and Sensibi...|[Haifa,  Eilat,  ...|    [Drama, Romance]|[United Kingdom, ...|           [English]|[Columbia Picture...|\n",
            "|       5|It's Ted the Bell...|          09/12/1995|             4300000|Twelve outrageous...|          Four Rooms|[Haifa,  Eilat,  ...|     [Crime, Comedy]|[United States of...|           [English]|[Miramax Films,  ...|\n",
            "|    9273|Summoned from an ...|          10/11/1995|           212385533|New animals. New ...|Ace Ventura: When...|[Tiberias,  Tel A...|[Crime, Comedy, A...|[United States of...|           [English]|[O Entertainment,...|\n",
            "|   11517|A vengeful New Yo...|          21/11/1995|            35431113|Get on, or GET OU...|         Money Train|[Eilat,  Jerusale...|[Action, Comedy, ...|[United States of...|           [English]| [Columbia Pictures]|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2 - Data Analysis\n",
        "\n",
        "# Insight 1: Tel Aviv is the most queried city with 44721 lookups, Jerusalem is right after with 34561\n",
        "# and then Haifa, Tiberias and Eilat with 22712, 9594 and 17348 lookups respectively\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  for city in row.cities:\n",
        "    counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"Insight 1: Tel Aviv is the most queried city with 44721 lookups, Jerusalem is right after with 34561, and then Haifa, Tiberias and Eilat with 22712, 9594 and 17348 lookups respectively\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "# Insight 2: Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "            \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "\n",
        "for row in queries_itr:\n",
        "  if \" עִבְרִית\" in row.lang:\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                  \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                  \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                  \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                  \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"Insight 2: Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "\n",
        "# Insight 3: Jerusalemites care about the playing actors, Haifa people care \n",
        "# about directors, and Eilaties alaways specify countries in their queries.\n",
        "print(\"Insight 3: Jerusalemites care about the playing actors, Haifa people care about directors, and Eilaties alaways specify countries in their queries.\")\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.actors[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print()\n",
        "print(\"actors empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.director[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"director empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.country[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"country empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "# Insight 4: people who look for movies in Eilat, never look for movies in over places in the same query\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "city_lookup_dict = {}\n",
        "for row in queries_itr:\n",
        "  key = \" \".join(str(x) for x in row.cities)\n",
        "  if key not in city_lookup_dict.keys():\n",
        "    city_lookup_dict[key] = 1\n",
        "  else:\n",
        "    city_lookup_dict[key] += 1\n",
        "print(\"Insight 4: people who look for movies in Eilat, never look for movies in over places in the same query\")\n",
        "print(\"Lookups for cinemas in different cities counts\")\n",
        "print(city_lookup_dict)\n",
        "print()\n",
        "\n",
        "# Insight 5: the number of tickets in reservations are more or less in the same amount and from the same distribution\n",
        "print(\"Insight 5: the number of tickets in reservations are more or less in the same amount and from the same distribution\")\n",
        "import pandas as pd\n",
        "tickets_by_city = [[\"Tel Aviv\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [\"Jerusalem\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                   [\"Haifa\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [\"Tiberias\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                   [\"Eilat\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "tickets_by_city = pd.DataFrame(tickets_by_city, columns=[\"City\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"])\n",
        "tickets_by_city.set_index(\"City\", inplace=True)\n",
        "\n",
        "tickets_df = spark.read.csv('tickets.csv', header='True', inferSchema='True')\n",
        "tickets_itr = tickets_df.rdd.toLocalIterator()\n",
        "for row in tickets_itr:\n",
        "  tickets_by_city.at[row.city, str(row.number_of_tickets)] += 1\n",
        "\n",
        "print(\"Number of tickets per reservation count by city\")\n",
        "print(tickets_by_city)\n",
        "print()\n",
        "ax = tickets_by_city.plot.bar(rot=0)"
      ],
      "metadata": {
        "id": "WS6omS_gYdLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanations for the data analysis section\n",
        "\n",
        "In this part of the project we have chosen to focus on finding insights mainly from the \"queries\" table as well as from the \"tickets\" table, and in particular those that will help us in the horizontal fregmentation, since the vertical fregmenataion is more easy to implement by code and the horizontal is more dependent on our previous knowladge about the database.\n",
        "\n",
        "Since the general task in this part of the project is to divide the database between sites that are geographically close to the cities of Haifa, Tiberias, Tel Aviv, Jerusalem and Eilat, we found it appropriate to focus on the differences embodied in the database between the cities, hoping that if we find significant differences between cities, we would be able to generalize them for certain rows / columns in the database.\n",
        "\n",
        "Indeed, we have found some interesting insights, as one can see from the above code output:\n",
        "\n",
        "1. Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew.\n",
        "2. Jerusalemites care much about the playing actors, Haifa people care much about directors, and Eilaties alaways specify countries in their queries.\n",
        "3. People who look for movies in Eilat, never look for movies in over places in the same query.\n",
        "4. The numbers of tickets in reservations are more or less in the same amount and from the same distribution.\n"
      ],
      "metadata": {
        "id": "HC3NC8wp1bfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def row_counter(my_array):\n",
        "    # count identical rows in matrix\n",
        "    list_of_tups = [tuple(ele) for ele in my_array]\n",
        "    return Counter(list_of_tups)\n",
        "\n",
        "# build use matrix for queries and shrink it\n",
        "shape = (queries_df.count(), len(queries_df.columns))\n",
        "queries_use = np.zeros(shape)\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "for i, row in enumerate(queries_itr):\n",
        "  for j, col in enumerate(queries_df.columns):\n",
        "    if type(row[col]) != list:\n",
        "      queries_use[i, j] = 1\n",
        "    else:\n",
        "      queries_use[i, j] = 0 if row[col][0] == \"\" else 1\n",
        "\n",
        "access = row_counter(queries_use)\n",
        "\n",
        "for key, value in access.items():\n",
        "    print(f\"{key} : {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8uA1cuPgxrx",
        "outputId": "b3b489da-6f78-41f7-e69d-0ac5c52c7ea1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0) : 10046\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0) : 12416\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 31305\n",
            "(1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 965\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 21205\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0) : 12620\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0) : 9983\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 1308\n",
            "(1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 64\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0) : 3\n",
            "(1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 3\n",
            "(1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 70\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0) : 5\n",
            "(1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 4\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0) : 1\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0) : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_queries = 8\n",
        "n_attributes = 9\n",
        "#attribute usage matrix\n",
        "aum = [[1, 1, 1, 0, 1, 1, 0, 1, 1],  # 10046\n",
        "       [1, 1, 1, 0, 0, 1, 0, 1, 1],  # 12416\n",
        "       [1, 1, 1, 1, 0, 1, 1, 1, 1],  # 31305\n",
        "       [1, 1, 1, 0, 1, 1, 1, 1, 1],  # 965\n",
        "       [1, 1, 1, 0, 0, 1, 1, 1, 1],  # 21205\n",
        "       [1, 1, 1, 1, 0, 1, 0, 1, 1],  # 12620\n",
        "       [1, 1, 1, 1, 1, 1, 0, 1, 1],  # 9983\n",
        "       [1, 1, 1, 1, 1, 1, 1, 1, 1]]  # 1308\n",
        "\n",
        "#number of sites\n",
        "n_sites = 5\n",
        "\n",
        "#access matrix\n",
        "acc = [[10046/100000, 10046/100000, 10046/100000, 10046/100000, 10046/100000],\n",
        "       [12416/100000, 12416/100000, 12416/100000, 12416/100000, 12416/100000],\n",
        "       [31305/100000, 31305/100000, 31305/100000, 31305/100000, 31305/100000],\n",
        "       [965/100000, 965/100000, 965/100000, 965/100000, 965/100000],\n",
        "       [21205/100000, 21205/100000, 21205/100000, 21205/100000, 21205/100000],\n",
        "       [12620/100000, 12620/100000, 12620/100000, 12620/100000, 12620/100000],\n",
        "       [9983/100000, 9983/100000, 9983/100000, 9983/100000, 9983/100000],\n",
        "       [1308/100000, 1308/100000, 1308/100000, 1308/100000, 1308/100000]]\n",
        "\n",
        "#prefix sum for each query\n",
        "pre = [0 for i in range(n_queries)]\n",
        "for i in range(n_queries):\n",
        "    for j in range(n_sites):\n",
        "        pre[i] = pre[i]+acc[i][j]\n",
        "\n",
        "#attribute affinity matrix\n",
        "aam = [[0 for i in range(n_attributes)] for j in range(n_attributes)]\n",
        "\n",
        "#calculation of the aam\n",
        "for i in range(n_attributes):\n",
        "    for j in range(n_attributes):\n",
        "         if(i==j):\n",
        "             aam[i][j]=0\n",
        "             continue\n",
        "         for q in range(n_queries):\n",
        "            if aum[q][i]==1 and aum[q][j]==1:\n",
        "                aam[i][j] = aam[i][j]+pre[q]\n",
        "          \n",
        "print(\"Attribute affinity matrix\")\n",
        "for i in range(n_attributes):\n",
        "    print(aam[i])\n",
        "print(\"Access Site Sums\")\n",
        "print(pre)"
      ],
      "metadata": {
        "id": "n7dxhJqPgED3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f39886-73d5-402a-8d7f-0a3bccada21f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute affinity matrix\n",
            "[0, 4.9924, 4.9924, 2.7608, 1.1151, 4.9924, 2.73915, 4.9924, 4.9924]\n",
            "[4.9924, 0, 4.9924, 2.7608, 1.1151, 4.9924, 2.73915, 4.9924, 4.9924]\n",
            "[4.9924, 4.9924, 0, 2.7608, 1.1151, 4.9924, 2.73915, 4.9924, 4.9924]\n",
            "[2.7608, 2.7608, 2.7608, 0, 0.56455, 2.7608, 1.63065, 2.7608, 2.7608]\n",
            "[1.1151, 1.1151, 1.1151, 0.56455, 0, 1.1151, 0.11365, 1.1151, 1.1151]\n",
            "[4.9924, 4.9924, 4.9924, 2.7608, 1.1151, 0, 2.73915, 4.9924, 4.9924]\n",
            "[2.73915, 2.73915, 2.73915, 1.63065, 0.11365, 2.73915, 0, 2.73915, 2.73915]\n",
            "[4.9924, 4.9924, 4.9924, 2.7608, 1.1151, 4.9924, 2.73915, 0, 4.9924]\n",
            "[4.9924, 4.9924, 4.9924, 2.7608, 1.1151, 4.9924, 2.73915, 4.9924, 0]\n",
            "Access Site Sums\n",
            "[0.5023, 0.6208, 1.56525, 0.04825, 1.06025, 0.631, 0.49915, 0.0654]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bond(Ax,Ay):\n",
        "    if Ax==-1 or Ay==-1:\n",
        "        return 0\n",
        "    ans = 0\n",
        "    for i in range(n_attributes):\n",
        "        ans = ans + (aam[i][Ax]*aam[i][Ay])\n",
        "    return ans\n",
        "\n",
        "def cont(Ai,Ak,Aj):\n",
        "    print(\"bond \",Ai, \"bond\", Ak, \" = \", bond(Ai,Ak))\n",
        "    print(\"bond \",Ak, \"bond\", Aj, \" = \", bond(Ak,Aj))\n",
        "    print(\"bond \",Ai, \"bond\", Aj, \" = \", bond(Ai,Aj))\n",
        "    return 2*bond(Ai,Ak) + 2*bond(Ak,Aj) - 2*bond(Ai,Aj)"
      ],
      "metadata": {
        "id": "PCkGAWkFgcmh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bond energy algorithm\n",
        "def BEA():\n",
        "    ca = []\n",
        "    ca.append(0)\n",
        "    ca.append(1)\n",
        "    index  = 2\n",
        "    while index < n_attributes:\n",
        "        maxi = -1 \n",
        "        maxc = -100000\n",
        "        for i in range(1,index):\n",
        "                con = cont(ca[i-1],index,ca[i])\n",
        "                print(\"Index \", i+1, \" \", \"cont \", ca[i],index+1,ca[i]+1, con)\n",
        "                if con > maxc:\n",
        "                    maxi = i\n",
        "                    maxc = con\n",
        "        #boundary left\n",
        "        con = cont(-1,index,ca[0])\n",
        "        print(\"Index \", i+1, \" \", \"cont \", 1,index+1,ca[0]+1, con)\n",
        "        if con > maxc:\n",
        "            maxi = 0\n",
        "            maxc = con\n",
        "        #boundary right\n",
        "        con = cont(ca[index-1],index,-1)\n",
        "        print(\"Index \", i+1, \" \", \"cont \", ca[index-1]+1,index+1,index+2, con)\n",
        "        if con > maxc:\n",
        "            maxi = index\n",
        "        if maxi==index:\n",
        "            ca.append(index)    \n",
        "        else:\n",
        "            ca.append(0)\n",
        "            for j in range(index,maxi,-1):\n",
        "                ca[j]=ca[j-1]\n",
        "            ca[maxi] = index\n",
        "        print(ca)\n",
        "        index = index + 1\n",
        "    print(\"FINAL Clustered Affinity Matrix\")\n",
        "    print(ca)\n",
        "    return ca"
      ],
      "metadata": {
        "id": "RU1lcD4_gf4I"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CA = BEA()\n",
        "ca = [[0 for i in range(n_attributes)] for j in range(n_attributes)]\n",
        "for i in range(n_attributes):\n",
        "    for j in range(n_attributes):\n",
        "        ca[i][j] = aam[CA[i]][CA[j]]\n",
        "\n",
        "print(ca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9nR9M3CghV4",
        "outputId": "c299860f-1c06-4a30-cbc2-cd5a7ad0ae18"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bond  0 bond 2  =  165.9127539325\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "bond  0 bond 1  =  165.9127539325\n",
            "Index  2   cont  1 3 2 331.825507865\n",
            "bond  -1 bond 2  =  0\n",
            "bond  2 bond 0  =  165.9127539325\n",
            "bond  -1 bond 0  =  0\n",
            "Index  2   cont  1 3 1 331.825507865\n",
            "bond  1 bond 2  =  165.9127539325\n",
            "bond  2 bond -1  =  0\n",
            "bond  1 bond -1  =  0\n",
            "Index  2   cont  2 3 4 331.825507865\n",
            "[0, 2, 1]\n",
            "bond  0 bond 3  =  95.41624881250002\n",
            "bond  3 bond 2  =  95.41624881250002\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  2   cont  2 4 3 49.83948738500004\n",
            "bond  2 bond 3  =  95.41624881250002\n",
            "bond  3 bond 1  =  95.41624881250002\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  3   cont  1 4 2 49.83948738500004\n",
            "bond  -1 bond 3  =  0\n",
            "bond  3 bond 0  =  95.41624881250002\n",
            "bond  -1 bond 0  =  0\n",
            "Index  3   cont  1 4 1 190.83249762500003\n",
            "bond  1 bond 3  =  95.41624881250002\n",
            "bond  3 bond -1  =  0\n",
            "bond  1 bond -1  =  0\n",
            "Index  3   cont  2 4 5 190.83249762500003\n",
            "[3, 0, 2, 1]\n",
            "bond  3 bond 4  =  20.8448711975\n",
            "bond  4 bond 0  =  36.5155134875\n",
            "bond  3 bond 0  =  95.41624881250002\n",
            "Index  2   cont  0 5 1 -76.11172825500003\n",
            "bond  0 bond 4  =  36.5155134875\n",
            "bond  4 bond 2  =  36.5155134875\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  3   cont  2 5 3 -185.763453915\n",
            "bond  2 bond 4  =  36.5155134875\n",
            "bond  4 bond 1  =  36.5155134875\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  4   cont  1 5 2 -185.763453915\n",
            "bond  -1 bond 4  =  0\n",
            "bond  4 bond 3  =  20.8448711975\n",
            "bond  -1 bond 3  =  0\n",
            "Index  4   cont  1 5 4 41.689742395\n",
            "bond  1 bond 4  =  36.5155134875\n",
            "bond  4 bond -1  =  0\n",
            "bond  1 bond -1  =  0\n",
            "Index  4   cont  2 5 6 73.031026975\n",
            "[3, 0, 2, 1, 4]\n",
            "bond  3 bond 5  =  95.41624881250002\n",
            "bond  5 bond 0  =  165.9127539325\n",
            "bond  3 bond 0  =  95.41624881250002\n",
            "Index  2   cont  0 6 1 331.825507865\n",
            "bond  0 bond 5  =  165.9127539325\n",
            "bond  5 bond 2  =  165.9127539325\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  3   cont  2 6 3 331.825507865\n",
            "bond  2 bond 5  =  165.9127539325\n",
            "bond  5 bond 1  =  165.9127539325\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  4   cont  1 6 2 331.825507865\n",
            "bond  1 bond 5  =  165.9127539325\n",
            "bond  5 bond 4  =  36.5155134875\n",
            "bond  1 bond 4  =  36.5155134875\n",
            "Index  5   cont  4 6 5 331.82550786499996\n",
            "bond  -1 bond 5  =  0\n",
            "bond  5 bond 3  =  95.41624881250002\n",
            "bond  -1 bond 3  =  0\n",
            "Index  5   cont  1 6 4 190.83249762500003\n",
            "bond  4 bond 5  =  36.5155134875\n",
            "bond  5 bond -1  =  0\n",
            "bond  4 bond -1  =  0\n",
            "Index  5   cont  5 6 7 73.031026975\n",
            "[3, 5, 0, 2, 1, 4]\n",
            "bond  3 bond 6  =  54.406126495\n",
            "bond  6 bond 5  =  94.18116711749998\n",
            "bond  3 bond 5  =  95.41624881250002\n",
            "Index  2   cont  5 7 6 106.34208959999995\n",
            "bond  5 bond 6  =  94.18116711749998\n",
            "bond  6 bond 0  =  94.18116711749998\n",
            "bond  5 bond 0  =  165.9127539325\n",
            "Index  3   cont  0 7 1 44.899160604999906\n",
            "bond  0 bond 6  =  94.18116711749998\n",
            "bond  6 bond 2  =  94.18116711749998\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  4   cont  2 7 3 44.899160604999906\n",
            "bond  2 bond 6  =  94.18116711749998\n",
            "bond  6 bond 1  =  94.18116711749998\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  5   cont  1 7 2 44.899160604999906\n",
            "bond  1 bond 6  =  94.18116711749998\n",
            "bond  6 bond 4  =  19.68517596\n",
            "bond  1 bond 4  =  36.5155134875\n",
            "Index  6   cont  4 7 5 154.70165917999995\n",
            "bond  -1 bond 6  =  0\n",
            "bond  6 bond 3  =  54.406126495\n",
            "bond  -1 bond 3  =  0\n",
            "Index  6   cont  1 7 4 108.81225299\n",
            "bond  4 bond 6  =  19.68517596\n",
            "bond  6 bond -1  =  0\n",
            "bond  4 bond -1  =  0\n",
            "Index  6   cont  5 7 8 39.37035192\n",
            "[3, 5, 0, 2, 1, 6, 4]\n",
            "bond  3 bond 7  =  95.41624881250002\n",
            "bond  7 bond 5  =  165.9127539325\n",
            "bond  3 bond 5  =  95.41624881250002\n",
            "Index  2   cont  5 8 6 331.825507865\n",
            "bond  5 bond 7  =  165.9127539325\n",
            "bond  7 bond 0  =  165.9127539325\n",
            "bond  5 bond 0  =  165.9127539325\n",
            "Index  3   cont  0 8 1 331.825507865\n",
            "bond  0 bond 7  =  165.9127539325\n",
            "bond  7 bond 2  =  165.9127539325\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  4   cont  2 8 3 331.825507865\n",
            "bond  2 bond 7  =  165.9127539325\n",
            "bond  7 bond 1  =  165.9127539325\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  5   cont  1 8 2 331.825507865\n",
            "bond  1 bond 7  =  165.9127539325\n",
            "bond  7 bond 6  =  94.18116711749998\n",
            "bond  1 bond 6  =  94.18116711749998\n",
            "Index  6   cont  6 8 7 331.8255078650001\n",
            "bond  6 bond 7  =  94.18116711749998\n",
            "bond  7 bond 4  =  36.5155134875\n",
            "bond  6 bond 4  =  19.68517596\n",
            "Index  7   cont  4 8 5 222.02300928999998\n",
            "bond  -1 bond 7  =  0\n",
            "bond  7 bond 3  =  95.41624881250002\n",
            "bond  -1 bond 3  =  0\n",
            "Index  7   cont  1 8 4 190.83249762500003\n",
            "bond  4 bond 7  =  36.5155134875\n",
            "bond  7 bond -1  =  0\n",
            "bond  4 bond -1  =  0\n",
            "Index  7   cont  5 8 9 73.031026975\n",
            "[3, 5, 0, 2, 1, 7, 6, 4]\n",
            "bond  3 bond 8  =  95.41624881250002\n",
            "bond  8 bond 5  =  165.9127539325\n",
            "bond  3 bond 5  =  95.41624881250002\n",
            "Index  2   cont  5 9 6 331.825507865\n",
            "bond  5 bond 8  =  165.9127539325\n",
            "bond  8 bond 0  =  165.9127539325\n",
            "bond  5 bond 0  =  165.9127539325\n",
            "Index  3   cont  0 9 1 331.825507865\n",
            "bond  0 bond 8  =  165.9127539325\n",
            "bond  8 bond 2  =  165.9127539325\n",
            "bond  0 bond 2  =  165.9127539325\n",
            "Index  4   cont  2 9 3 331.825507865\n",
            "bond  2 bond 8  =  165.9127539325\n",
            "bond  8 bond 1  =  165.9127539325\n",
            "bond  2 bond 1  =  165.9127539325\n",
            "Index  5   cont  1 9 2 331.825507865\n",
            "bond  1 bond 8  =  165.9127539325\n",
            "bond  8 bond 7  =  165.9127539325\n",
            "bond  1 bond 7  =  165.9127539325\n",
            "Index  6   cont  7 9 8 331.825507865\n",
            "bond  7 bond 8  =  165.9127539325\n",
            "bond  8 bond 6  =  94.18116711749998\n",
            "bond  7 bond 6  =  94.18116711749998\n",
            "Index  7   cont  6 9 7 331.8255078650001\n",
            "bond  6 bond 8  =  94.18116711749998\n",
            "bond  8 bond 4  =  36.5155134875\n",
            "bond  6 bond 4  =  19.68517596\n",
            "Index  8   cont  4 9 5 222.02300928999998\n",
            "bond  -1 bond 8  =  0\n",
            "bond  8 bond 3  =  95.41624881250002\n",
            "bond  -1 bond 3  =  0\n",
            "Index  8   cont  1 9 4 190.83249762500003\n",
            "bond  4 bond 8  =  36.5155134875\n",
            "bond  8 bond -1  =  0\n",
            "bond  4 bond -1  =  0\n",
            "Index  8   cont  5 9 10 73.031026975\n",
            "[3, 5, 0, 2, 1, 7, 8, 6, 4]\n",
            "FINAL Clustered Affinity Matrix\n",
            "[3, 5, 0, 2, 1, 7, 8, 6, 4]\n",
            "[[2.7608, 2.7608, 2.7608, 2.7608, 2.7608, 2.7608, 2.7608, 1.63065, 0.56455], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [2.7608, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 4.9924, 2.73915, 1.1151], [1.63065, 2.73915, 2.73915, 2.73915, 2.73915, 2.73915, 2.73915, 2.73915, 0.11365], [0.56455, 1.1151, 1.1151, 1.1151, 1.1151, 1.1151, 1.1151, 0.11365, 1.1151]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def shift_row_aum(mat):\n",
        "    row_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        row_first.append(mat[0][i])\n",
        "    for i in range(1,n_queries):\n",
        "        for j in range(n_attributes):\n",
        "            mat[i-1][j]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[n_queries-1][i]=row_first[i]\n",
        "   # print(row_first)\n",
        "    return mat\n",
        "   \n",
        "def shift_column_aum(mat):\n",
        "    col_first=[]\n",
        "    for i in range(n_queries):\n",
        "        col_first.append(mat[i][0])\n",
        "    for i in range(n_queries):\n",
        "        for j in range(1,n_attributes):\n",
        "            mat[i][j-1]=mat[i][j]\n",
        "    for i in range(n_queries):\n",
        "        mat[i][n_attributes-1]=col_first[i]\n",
        "    return mat"
      ],
      "metadata": {
        "id": "YpjTo6PsgjPL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shift_row_ca(mat):\n",
        "    row_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        row_first.append(mat[0][i])\n",
        "    for i in range(1,n_attributes):\n",
        "        for j in range(n_attributes):\n",
        "            mat[i-1][j]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[n_attributes-1][i]=row_first[i]\n",
        "   # print(row_first)\n",
        "    return mat\n",
        "   \n",
        "def shift_column_ca(mat):\n",
        "    col_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        col_first.append(mat[i][0])\n",
        "    for i in range(n_attributes):\n",
        "        for j in range(1,n_attributes):\n",
        "            mat[i][j-1]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[i][n_attributes-1]=col_first[i]\n",
        "    return mat"
      ],
      "metadata": {
        "id": "CsZbZvoIglUP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Partioning\n",
        "start=n_attributes-2\n",
        "aum = [[1, 1, 1, 0, 1, 1, 0, 1, 1],  # 10046\n",
        "       [1, 1, 1, 0, 0, 1, 0, 1, 1],  # 12416\n",
        "       [1, 1, 1, 1, 0, 1, 1, 1, 1],  # 31305\n",
        "       [1, 1, 1, 0, 1, 1, 1, 1, 1],  # 965\n",
        "       [1, 1, 1, 0, 0, 1, 1, 1, 1],  # 21205\n",
        "       [1, 1, 1, 1, 0, 1, 0, 1, 1],  # 12620\n",
        "       [1, 1, 1, 1, 1, 1, 0, 1, 1],  # 9983\n",
        "       [1, 1, 1, 1, 1, 1, 1, 1, 1]]  # 1308\n",
        "AQ=[]\n",
        "for i in range(n_queries):\n",
        "    row=[]\n",
        "    for j in range(n_attributes):\n",
        "        if aum[i][j]==1:\n",
        "            row.append(j)\n",
        "    AQ.append(row)\n",
        "\n",
        "print(AQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCGFJpnvgnQr",
        "outputId": "79f5d82c-1cff-46c1-b9d8-885dc7f6cdc5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2, 4, 5, 7, 8], [0, 1, 2, 5, 7, 8], [0, 1, 2, 3, 5, 6, 7, 8], [0, 1, 2, 4, 5, 6, 7, 8], [0, 1, 2, 5, 6, 7, 8], [0, 1, 2, 3, 5, 7, 8], [0, 1, 2, 3, 4, 5, 7, 8], [0, 1, 2, 3, 4, 5, 6, 7, 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TQ=[]\n",
        "BQ=[]\n",
        "OQ=[]\n",
        "\n",
        "for i in range(n_queries):\n",
        "    if AQ[i][1] <= start:\n",
        "        TQ.append(i)\n",
        "    elif AQ[i][0] > start:\n",
        "        BQ.append(i)\n",
        "    else:\n",
        "        OQ.append(i)\n",
        "\n",
        "    \n",
        "print(TQ)\n",
        "print(BQ)\n",
        "print(OQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyBXMuz6gqZt",
        "outputId": "e95af64d-e22f-4b91-8672-e42fafe89412"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CTQ=0\n",
        "CBQ=0\n",
        "COQ=0\n",
        "\n",
        "for i in range(len(TQ)):\n",
        "    CTQ=CTQ+pre[TQ[i]]\n",
        "for i in range(len(BQ)):\n",
        "    CBQ=CBQ+pre[BQ[i]]\n",
        "for i in range(len(OQ)):\n",
        "    COQ=COQ+pre[OQ[i]]\n",
        "best=CTQ*CBQ-COQ*COQ"
      ],
      "metadata": {
        "id": "eOKZXPeygr70"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shift=0\n",
        "for i in range(n_sites):\n",
        "    for j in range(n_attributes-3,0,-1):\n",
        "        TQ=[]\n",
        "        BQ=[]\n",
        "        OQ=[]\n",
        "\n",
        "        for k in range(n_sites):\n",
        "            if AQ[k][1] <= j:\n",
        "                TQ.append(i)\n",
        "            elif AQ[k][0] > j:\n",
        "                BQ.append(k)\n",
        "            else:\n",
        "                OQ.append(k)\n",
        "        CTQ=0\n",
        "        CBQ=0\n",
        "        COQ=0\n",
        "        print(TQ)\n",
        "        for k in range(len(TQ)):\n",
        "            CTQ=CTQ+pre[TQ[k]]\n",
        "        for k in range(len(BQ)):\n",
        "            CBQ=CBQ+pre[BQ[k]]\n",
        "        for k in range(len(OQ)):\n",
        "            COQ=COQ+pre[OQ[k]]\n",
        "        z=CTQ*CBQ-COQ*COQ\n",
        "        if z>best:\n",
        "            best=z\n",
        "            start=j\n",
        "            shift=i\n",
        "    shift_row_ca(ca)\n",
        "    shift_column_ca(ca)\n",
        "    shift_row_aum(aum)\n",
        "    shift_column_aum(aum)\n",
        "    AQ=[]\n",
        "    for i in range(n_queries):\n",
        "        row=[]\n",
        "        for j in range(n_attributes):\n",
        "            if aum[i][j]==1:\n",
        "                row.append(j)\n",
        "        AQ.append(row)\n",
        "last=n_attributes-1\n",
        "for i in range(shift):\n",
        "    ele=CA[last]\n",
        "    for j in range(last,1,-1):\n",
        "        CA[j]=CA[j-1]\n",
        "    CA[0]=ele\n",
        "F1={1}\n",
        "F2={1}\n",
        "print(\"First Half\")\n",
        "for i in range(0,start):\n",
        "    F1.add(CA[i]+1)\n",
        "print(F1)    \n",
        "print(\"Second Half\")\n",
        "\n",
        "for i in range(start,n_attributes):\n",
        "    F2.add(CA[i]+1)\n",
        "print(F2)  \n",
        "print(\"Split is:\")\n",
        "print(start)\n",
        "print(\"Shift is\")\n",
        "print(shift)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VXi8pN-guNs",
        "outputId": "83ebcf30-c439-4a17-affc-91301ed6ebc8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2]\n",
            "[2, 2, 2]\n",
            "[3, 3, 3, 3, 3]\n",
            "[3, 3, 3, 3, 3]\n",
            "[3, 3, 3, 3, 3]\n",
            "[3, 3, 3, 3, 3]\n",
            "[3, 3, 3, 3]\n",
            "[3, 3]\n",
            "[4, 4, 4, 4, 4]\n",
            "[4, 4, 4, 4, 4]\n",
            "[4, 4, 4, 4, 4]\n",
            "[4, 4, 4, 4, 4]\n",
            "[4, 4, 4, 4]\n",
            "[4, 4, 4]\n",
            "First Half\n",
            "{1, 2, 3, 4, 6, 8, 9}\n",
            "Second Half\n",
            "{1, 5, 7}\n",
            "Split is:\n",
            "7\n",
            "Shift is\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}