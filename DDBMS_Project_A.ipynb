{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDBMS_Project_A.ipynb",
      "provenance": [],
      "mount_file_id": "1mBUyIojQQQ8ry0SGEUnkNXoFP2jG1OJM",
      "authorship_tag": "ABX9TyMOtGHxw45kNNVxdkpefD1a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MShiloni22/DDBMS_Project_A/blob/master/DDBMS_Project_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mWNnZ2cu78n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca17a24-5be6-4f47-bbaf-2f6847ad0d1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdHZG53o8Q4D",
        "outputId": "8157493b-d7c4-490a-b884-bff2e0d6b687"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 65.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=96422c6f61885d8d167869e3f504ce4d958e843388e8ae1fc1235ebc5dd660f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "import datetime as dt\n",
        "\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "def init_spark(app_name: str):\n",
        " spark = SparkSession.builder.appName(app_name).getOrCreate()\n",
        " sc = spark.sparkContext\n",
        " return spark, sc\n",
        "spark, sc = init_spark('demo')\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "qVknTdsu8bUx",
        "outputId": "8164d2f8-7150-4800-e94d-10161a369a1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=demo>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bacd571855e5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# working on queries.csv extraction\n",
        "from pyspark.sql import SparkSession,Row, Column\n",
        "import pyspark.sql.functions as F\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "queries_file = '/content/drive/MyDrive/Colab Files/DDBMS//queries.csv'\n",
        "df = spark.read.csv(queries_file, header='True', inferSchema='True')\n",
        "\n",
        "print(\"Loaded queries successfully\")\n",
        "\n",
        "# doing the same process for all columns\n",
        "column_names = [\"genres\", \"lang\", \"actors\", \"director\", \"cities\", \"country\", \n",
        "                \"from_realese_date\", \"production_company\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"'[]\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Cleaned and seperated to arrays\")\n",
        "\n",
        "# creating columns for each element in each column contains an array\n",
        "# for name in column_names:\n",
        "#   name_size = name + \"_size\"\n",
        "#   # get max array's size in the column\n",
        "#   df = df.withColumn(name_size, F.size(F.col(name)))\n",
        "#   df_col_max = df.agg({name_size: 'max'})\n",
        "#   max_col_size = df_col_max.collect()[0][0]\n",
        "\n",
        "#   for i in range(max_col_size):\n",
        "#     df = df.withColumn(name + \"_\" + str(i), F.col(name)[i])\n",
        "\n",
        "#   df = df.drop(name)\n",
        "#   df = df.drop(name_size)\n",
        "\n",
        "df.show()\n",
        "queries_df = df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrMrtAb2LPXp",
        "outputId": "03d5ac5e-d743-4f21-b837-f011c74a97af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded queries successfully\n",
            "Cleaned and seperated to arrays\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|user_id|              genres|                lang|              actors|            director|              cities|             country|from_realese_date|  production_company|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|    981| [Western,  Mystery]|  [English,  Srpski]|                  []|      [Nae Caranfil]|  [Haifa,  Tiberias]|                  []|           [2012]|[Katakuri-ke no K...|\n",
            "|   3775|  [Action,  Western]|           [English]|                  []|                  []|          [Tel Aviv]|                  []|           [2013]|[Clavius Base,  T...|\n",
            "|   4095|             [Crime]|[English,  עִבְרִית]|[Kenneth Alton,  ...|                  []|         [Jerusalem]| [Belgium,  Moldova]|           [1995]|[Peter Carsten Pr...|\n",
            "|   3363|[Animation,  West...|           [English]|                  []|      [Philip Dunne]|             [Haifa]|           [Croatia]|           [2014]|[Centrul de Produ...|\n",
            "|   8982|[Action,  Documen...|           [English]|                  []|                  []|[Tel Aviv,  Jerus...|                  []|           [2018]|[Vortex Words Pic...|\n",
            "|   7603|          [TV Movie]|           [English]|[Tom Hanks,  Stua...|                  []|         [Jerusalem]|  [Jamaica,  Israel]|           [1999]|   [Northern Lights]|\n",
            "|   3112|[Fantasy,  Advent...|           [English]|                  []|                  []|             [Eilat]|[Guatemala,  Kyrg...|           [1996]|[Warner Bros,  Pi...|\n",
            "|   7217|[Drama,  Animatio...|[English,  עִבְרִית]|                  []|                  []|         [Jerusalem]|    [Qatar,  Israel]|           [1999]|             [Chill]|\n",
            "|   9716|   [Crime,  Romance]|           [English]|                  []|                  []|             [Eilat]|[Switzerland,  Mo...|           [2006]|[Monogram Picture...|\n",
            "|   4832|[Drama,  Animatio...|           [English]|                  []|    [Michael Tiddes]|             [Haifa]|                  []|           [2012]|[Joel Productions...|\n",
            "|   8260|            [Family]|           [English]| [\"\"\"Terry OQuinn\"\"]|  [ Johnny Larocque]|    [ Edward Walsh\"]|                  []|       [Tiberias]| [Namibia,  Morocco]|\n",
            "|   2772|   [Action,  Family]|           [English]|[Harry Carey,  Jr...|                  []|          [Tel Aviv]|                  []|           [2017]|[MGM-Pathé Commun...|\n",
            "|   8971|[Adventure,  Scie...|           [English]|                  []|                  []|             [Eilat]|  [Congo,  Ethiopia]|           [2004]|[Walt Disney Pict...|\n",
            "|  10496| [Drama,  Animation]|           [English]|[Osamu Hosoi,  Eu...|[Julia Sweeney,  ...|             [Haifa]|                  []|           [2016]|[RTV Slovenija,  ...|\n",
            "|   9658|[Drama,  Adventur...|           [English]|      [Otto Klopsch]|       [So Yong Kim]|             [Haifa]|                  []|           [2018]|[Rational Packagi...|\n",
            "|  10114|[Horror,  Adventure]| [English,  ภาษาไทย]|                  []|                  []|             [Eilat]|[Netherlands,  Ka...|           [2016]|[Walt Disney Pict...|\n",
            "|   2727|[Drama,  Adventur...|   [English,  ?????]|[Bernadette Leonard]|[Philippe Le Guay...|             [Haifa]|                  []|           [2018]|[HE-Filmproduktio...|\n",
            "|   1889|[Drama,  Horror, ...|           [English]|    [Hassan Majooni]|                  []|             [Haifa]|                  []|           [2016]|[\"\"\"Thats Nice Fi...|\n",
            "|   8235|    [Drama,  Action]|           [English]|        [Gil Herman]|      [Mariano Cohn]|             [Haifa]|                  []|           [2012]|[\"\"\"Centre Nation...|\n",
            "|   6345|[Animation,  Adve...|           [English]|                  []|                  []|             [Eilat]|[South Korea,  Mo...|           [2012]|[Pixar Animation ...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# working on credits.csv extraction\n",
        "import re\n",
        "credits_file = '/content/drive/MyDrive/Colab Files/DDBMS//credits.csv'\n",
        "df = spark.read.csv(credits_file, header='True', inferSchema='True')\n",
        "\n",
        "# load the data as you did before,\n",
        "# just now change the delimiter to get evreything together\n",
        "credits = spark.read.format(\"csv\")\\\n",
        ".option(\"delimiter\", \"\\t\")\\\n",
        ".option(\"header\",\"true\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".load(\"drive/MyDrive/Colab Files/DDBMS//credits.csv\")\n",
        "prog = re.compile('\\\\[(.*?)\\\\]')\n",
        "second_match = F.udf(lambda x: prog.findall(x)[1])\n",
        "id_extract = F.udf(lambda x: x.split(\",\")[-1])\n",
        "credits = credits\\\n",
        ".withColumn(\"id\", id_extract(\"cast,crew,id\"))\\\n",
        ".withColumn(\"cast\", F.regexp_extract(F.col(\"cast,crew,id\"), '\\\\[(.*?)\\\\]', 0\n",
        "))\\\n",
        ".withColumn(\"crew\", F.concat(F.lit(\"[\"),second_match(\"cast,crew,id\"), F.lit(\n",
        "\"]\")))\\\n",
        ".select(\"cast\", \"crew\", \"id\")\n",
        "df = credits\n",
        "# df.printSchema()\n",
        "print(\"Loaded credits successfully\")\n",
        "\n",
        "# doing the same process for all columns\n",
        "column_names = [\"cast\", \"crew\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # # converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Cleaned and seperated to arrays\")\n",
        "\n",
        "# for cast column - udf for extracting actors' names only from cast json string\n",
        "actors_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 8 == 5])\n",
        "df = df.withColumn('actors', actors_udf(F.col(\"cast\")))\\\n",
        "  .drop(\"cast\")\n",
        "\n",
        "# for crew column - udf for extracting directors'' names only from crew json string\n",
        "directors_udf = F.udf(lambda arr: [arr[i+1][7:] for i in range(len(arr))\n",
        " if arr[i] == \" job: Director\"])\n",
        "\n",
        "df = df.withColumn('directors', directors_udf(F.col(\"crew\")))\\\n",
        "  .drop(\"crew\")\n",
        "\n",
        "# converting arrays strings to arrays of strings\n",
        "column_names = [\"actors\", \"directors\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # # converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "# for name in column_names:\n",
        "#   name_size = name + \"_size\"\n",
        "#   # get max array's size in the column\n",
        "#   df = df.withColumn(name_size, F.size(F.col(name)))\n",
        "#   df_col_max = df.agg({name_size: 'max'})\n",
        "#   max_col_size = df_col_max.collect()[0][0]\n",
        "\n",
        "#   for i in range(max_col_size):\n",
        "#     df = df.withColumn(name + \"_\" + str(i), F.col(name)[i])\n",
        "\n",
        "#   df = df.drop(name)\n",
        "#   df = df.drop(name_size)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awuvXUqNApvp",
        "outputId": "d5b64ec7-9006-4bb2-f249-094a537e8f08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded credits successfully\n",
            "Cleaned and seperated to arrays\n",
            "+-----+--------------------+--------------------+\n",
            "|   id|              actors|           directors|\n",
            "+-----+--------------------+--------------------+\n",
            "|  862|[Tom Hanks,  Tim ...|     [John Lasseter]|\n",
            "| 8844|[Robin Williams, ...|      [Joe Johnston]|\n",
            "|15602|[Walter Matthau, ...|     [Howard Deutch]|\n",
            "|31357|[Whitney Houston,...|   [Forest Whitaker]|\n",
            "|11862|[Steve Martin,  D...|     [Charles Shyer]|\n",
            "|  949|[Al Pacino,  Robe...|      [Michael Mann]|\n",
            "|11860|[Harrison Ford,  ...|    [Sydney Pollack]|\n",
            "|45325|[Jonathan Taylor ...|      [Peter Hewitt]|\n",
            "| 9091|[Jean-Claude Van ...|       [Peter Hyams]|\n",
            "|  710|[Pierce Brosnan, ...|   [Martin Campbell]|\n",
            "| 9087|[Michael Douglas,...|        [Rob Reiner]|\n",
            "|12110|[Leslie Nielsen, ...|        [Mel Brooks]|\n",
            "|21032|[Kevin Bacon,  Bo...|       [Simon Wells]|\n",
            "|10858|[Anthony Hopkins,...|      [Oliver Stone]|\n",
            "| 1408|[Geena Davis,  Ma...|      [Renny Harlin]|\n",
            "|  524|[Robert De Niro, ...|   [Martin Scorsese]|\n",
            "| 4584|[Kate Winslet,  E...|           [Ang Lee]|\n",
            "|    5|[Tim Roth,  Anton...|[Allison Anders, ...|\n",
            "| 9273|[Jim Carrey,  Ian...|    [Steve Oedekerk]|\n",
            "|11517|[Wesley Snipes,  ...|      [Joseph Ruben]|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# working on movies.csv extraction\n",
        "movies_file = '/content/drive/MyDrive/Colab Files/DDBMS//movies.csv'\n",
        "df = spark.read.csv(movies_file, header='True', inferSchema='True')\n",
        "\n",
        "print(\"Loaded movies successfully\")\n",
        "# doing the same process for all columns\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\", \"cities\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # # converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Cleaned and seperated to arrays\")\n",
        "\n",
        "# finished working on cities column, and seperating production_companies\n",
        "# because it has different structure\n",
        "column_names = [\"genres\", \"production_countries\", \n",
        "                \"spoken_languages\"]\n",
        "\n",
        "# for each column - udf for extracting names only from json string\n",
        "name_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 2 == 1])\n",
        "for c in column_names:\n",
        "  c_1 = c + \"1\"\n",
        "  df = df.withColumn(c_1, name_udf(F.col(c)))\\\n",
        "    .drop(c)\n",
        "prod_udf = F.udf(lambda arr: [arr[i][6:] for i in range(len(arr)) if i % 2 == 0])\n",
        "df = df.withColumn(\"production_companies1\", prod_udf(F.col(\"production_companies\")))\\\n",
        "  .drop(\"production_companies\")\n",
        "\n",
        "# renameing columns names\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\"]\n",
        "for name in column_names:\n",
        "  current_name = name + \"1\"\n",
        "  df = df.withColumnRenamed(current_name,name)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN_pyKTkjccG",
        "outputId": "eea9e293-ab02-49a6-b6ea-0c1185e029e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded movies successfully\n",
            "Cleaned and seperated to arrays\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|movie_id|            overview|        release_date|             revenue|             tagline|               title|              cities|              genres|production_countries|    spoken_languages|production_companies|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     862|Led by Woody, And...|          30/10/1995|           373554033|                null|           Toy Story|[Eilat,  Tel Aviv...|[Animation, Comed...|[United States of...|           [English]|[Pixar Animation ...|\n",
            "|    8844|When siblings Jud...|          15/12/1995|           262797249|Roll the dice and...|             Jumanji|[Jerusalem,  Tibe...|[Adventure, Fanta...|[United States of...|[English, FranÃ§ais]|[TriStar Pictures...|\n",
            "|   15602|A family wedding ...|          22/12/1995|                   0|Still Yelling. St...|    Grumpier Old Men|[Eilat,  Haifa,  ...|   [Romance, Comedy]|[United States of...|           [English]|[Warner Bros.,  L...|\n",
            "|   31357|\"Cheated on, mist...| determined to fi...|[{'name': 'Twenti...|          22/12/1995|            81452156|[iso_639_1: en,  ...|[Comedy, Drama, R...|                  []|[United States of...|                 [e]|\n",
            "|   11862|Just when George ...|          10/02/1995|            76578911|Just When His Wor...|Father of the Bri...|[Haifa,  Jerusale...|            [Comedy]|[United States of...|           [English]|[Sandollar Produc...|\n",
            "|     949|Obsessive master ...|          15/12/1995|           187436818|A Los Angeles Cri...|                Heat|[Tiberias,  Jerus...|[Action, Crime, D...|[United States of...| [English, EspaÃ±ol]|[Regency Enterpri...|\n",
            "|   11860|An ugly duckling ...|          15/12/1995|                   0|You are cordially...|             Sabrina|[Eilat,  Jerusale...|   [Comedy, Romance]|[Germany, United ...|[FranÃ§ais, English]|[Paramount Pictur...|\n",
            "|   45325|A mischievous you...|          22/12/1995|                   0|The Original Bad ...|        Tom and Huck|[Haifa,  Jerusale...|[Action, Adventur...|[United States of...|  [English, Deutsch]|[Walt Disney Pict...|\n",
            "|    9091|International act...|          22/12/1995|            64350171|Terror goes into ...|        Sudden Death|[Tiberias,  Haifa...|[Action, Adventur...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|     710|James Bond must u...|          16/11/1995|           352194034|No limits. No fea...|           GoldenEye|[Eilat,  Tiberias...|[Adventure, Actio...|[United Kingdom, ...|[English, PÑÑÑ...|[United Artists, ...|\n",
            "|    9087|Widowed U.S. pres...|          17/11/1995|           107879496|Why can't the mos...|The American Pres...|[Haifa,  Tel Aviv...|[Comedy, Drama, R...|[United States of...|           [English]|[Columbia Picture...|\n",
            "|   12110|When a lawyer sho...|          22/12/1995|                   0|                null|Dracula: Dead and...|[Tiberias,  Jerus...|    [Comedy, Horror]|[France, United S...|  [English, Deutsch]|[Columbia Picture...|\n",
            "|   21032|An outcast half-w...|          22/12/1995|            11348324|Part Dog. Part Wo...|               Balto|[Jerusalem,  Haif...|[Family, Animatio...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|   10858|An all-star cast ...|          22/12/1995|            13681765|Triumphant in Vic...|               Nixon|[Eilat,  Haifa,  ...|    [History, Drama]|[United States of...|           [English]|[Hollywood Pictur...|\n",
            "|    1408|Morgan Adams and ...|          22/12/1995|            10017322|The Course Has Be...|    Cutthroat Island|[Tiberias,  Eilat...| [Action, Adventure]|[France, Germany,...|    [English, Latin]|[Le Studio Canal+...|\n",
            "|     524|The life of the g...|          22/11/1995|           116112375|No one stays at t...|              Casino|[Tel Aviv,  Eilat...|      [Drama, Crime]|[France, United S...|           [English]|[Universal Pictur...|\n",
            "|    4584|Rich Mr. Dashwood...|          13/12/1995|           135000000|Lose your heart a...|Sense and Sensibi...|[Haifa,  Eilat,  ...|    [Drama, Romance]|[United Kingdom, ...|           [English]|[Columbia Picture...|\n",
            "|       5|It's Ted the Bell...|          09/12/1995|             4300000|Twelve outrageous...|          Four Rooms|[Haifa,  Eilat,  ...|     [Crime, Comedy]|[United States of...|           [English]|[Miramax Films,  ...|\n",
            "|    9273|Summoned from an ...|          10/11/1995|           212385533|New animals. New ...|Ace Ventura: When...|[Tiberias,  Tel A...|[Crime, Comedy, A...|[United States of...|           [English]|[O Entertainment,...|\n",
            "|   11517|A vengeful New Yo...|          21/11/1995|            35431113|Get on, or GET OU...|         Money Train|[Eilat,  Jerusale...|[Action, Comedy, ...|[United States of...|           [English]| [Columbia Pictures]|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2 - Data Analysis\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  for city in row.cities:\n",
        "    try:\n",
        "      counters[city] += 1\n",
        "    except:\n",
        "      KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# \n",
        "print(\"Cities in queries count:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "# Insight 1\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "            \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "\n",
        "for row in queries_itr:\n",
        "  if \" עִבְרִית\" in row.lang:\n",
        "    for city in row.cities:\n",
        "      try:\n",
        "        counters[city] += 1\n",
        "      except:\n",
        "        KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                  \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                  \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                  \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                  \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# It's not profitable to allocate information about movies in hebrew\n",
        "# in sites other than Tel Aviv/Jeruselam\n",
        "print(\"Hebrew count by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "\n",
        "# Insight 2\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.actors[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      try:\n",
        "        counters[city] += 1\n",
        "      except:\n",
        "        KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# \n",
        "print(\"actors empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.director[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      try:\n",
        "        counters[city] += 1\n",
        "      except:\n",
        "        KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# \n",
        "print(\"director empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.country[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      try:\n",
        "        counters[city] += 1\n",
        "      except:\n",
        "        KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# \n",
        "print(\"country empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  for city in row.cities:\n",
        "    try:\n",
        "      counters[city] += int(row.from_realese_date[0])\n",
        "    except:\n",
        "      KeyError\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "# \n",
        "print(\"release year count by city:\")\n",
        "print(counters_final)\n",
        "print()"
      ],
      "metadata": {
        "id": "m9DKe1h1p33T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822c2a37-2580-4d3a-ab37-8cf592ff8da1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cities in queries count:\n",
            "{'Tel Aviv': 44526, 'Jerusalem': 34425, 'Haifa': 22596, 'Tiberias': 9545, 'Eilat': 17347}\n",
            "\n",
            "Hebrew count by city:\n",
            "{'Tel Aviv': 15887, 'Jerusalem': 26161, 'Haifa': 104, 'Tiberias': 56, 'Eilat': 67}\n",
            "\n",
            "actors empty by city:\n",
            "{'Tel Aviv': 13882, 'Jerusalem': 3322, 'Haifa': 11376, 'Tiberias': 4812, 'Eilat': 17347}\n",
            "\n",
            "director empty by city:\n",
            "{'Tel Aviv': 41974, 'Jerusalem': 33352, 'Haifa': 2774, 'Tiberias': 5453, 'Eilat': 16816}\n",
            "\n",
            "country empty by city:\n",
            "{'Tel Aviv': 25220, 'Jerusalem': 3569, 'Haifa': 20882, 'Tiberias': 4128, 'Eilat': 0}\n",
            "\n",
            "country empty by city:\n",
            "{'Tel Aviv': 88963019, 'Jerusalem': 68093979, 'Haifa': 45479663, 'Tiberias': 18944854, 'Eilat': 34155290}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}