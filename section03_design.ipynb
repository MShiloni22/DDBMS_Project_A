{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "section03_design.ipynb",
      "provenance": [],
      "mount_file_id": "1mBUyIojQQQ8ry0SGEUnkNXoFP2jG1OJM",
      "authorship_tag": "ABX9TyNbpXg9i/RsFfvIatPBQ0wd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MShiloni22/DDBMS_Project_A/blob/master/section03_design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mWNnZ2cu78n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0d7fa3-2f30-4326-8a81-d63cb7bc2a53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdHZG53o8Q4D",
        "outputId": "5be1e6d9-ec60-4e56-c6b3-6146ba77d9b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 61.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=6e59cff9535b14ccb2e2137b4a147d75b2400f78fa2851d75e864ae91a4406ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "import datetime as dt\n",
        "\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "def init_spark(app_name: str):\n",
        " spark = SparkSession.builder.appName(app_name).getOrCreate()\n",
        " sc = spark.sparkContext\n",
        " return spark, sc\n",
        "spark, sc = init_spark('demo')\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "qVknTdsu8bUx",
        "outputId": "4d2e6a98-c632-4614-a66c-9db4c87b8325"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=demo>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fb79564b0832:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #%%\n",
        "# !pip install pyspark\n",
        "# !pip install findspark\n",
        "# #%%\n",
        "# Current file = queries.csv\n",
        "\n",
        "# Transform the file to tsv format\n",
        "import csv\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Files/DDBMS//queries.csv','r') as csvin, open('queries.tsv', 'w') as tsvout:\n",
        "    csvin = csv.reader(csvin)\n",
        "    tsvout = csv.writer(tsvout, delimiter='\\t')\n",
        "    for row in csvin:\n",
        "        tsvout.writerow(row)\n",
        "\n",
        "from pyspark.sql import SparkSession,Row, Column\n",
        "import pyspark.sql.functions as F\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "queries_file = 'queries.tsv'\n",
        "df = spark.read.csv(queries_file, header='True', inferSchema='True', sep='\\t')\n",
        "\n",
        "\n",
        "column_names = [\"genres\", \"lang\", \"actors\", \"director\", \"cities\", \"country\", \n",
        "                \"from_realese_date\", \"production_company\"]\n",
        "# For all the above columns\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"'[]\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Queries table:\")\n",
        "df.show()\n",
        "queries_df = df\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Current file: credits.csv\n",
        "import re\n",
        "credits_file = '/content/drive/MyDrive/Colab Files/DDBMS//credits.csv'\n",
        "df = spark.read.csv(credits_file, header='True', inferSchema='True')\n",
        "\n",
        "# load the data as you did before,\n",
        "# just now change the delimiter to get evreything together\n",
        "credits = spark.read.format(\"csv\")\\\n",
        ".option(\"delimiter\", \"\\t\")\\\n",
        ".option(\"header\",\"true\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".load(\"drive/MyDrive/Colab Files/DDBMS//credits.csv\")\n",
        "prog = re.compile('\\\\[(.*?)\\\\]')\n",
        "second_match = F.udf(lambda x: prog.findall(x)[1])\n",
        "id_extract = F.udf(lambda x: x.split(\",\")[-1])\n",
        "credits = credits\\\n",
        ".withColumn(\"id\", id_extract(\"cast,crew,id\"))\\\n",
        ".withColumn(\"cast\", F.regexp_extract(F.col(\"cast,crew,id\"), '\\\\[(.*?)\\\\]', 0\n",
        "))\\\n",
        ".withColumn(\"crew\", F.concat(F.lit(\"[\"),second_match(\"cast,crew,id\"), F.lit(\n",
        "\"]\")))\\\n",
        ".select(\"cast\", \"crew\", \"id\")\n",
        "df = credits\n",
        "# df.printSchema()\n",
        "column_names = [\"cast\", \"crew\"]\n",
        "# For all the above columns\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "# For cast column - udf for extracting actors' names only from cast json string\n",
        "actors_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 8 == 5])\n",
        "df = df.withColumn('actors', actors_udf(F.col(\"cast\")))\\\n",
        "  .drop(\"cast\")\n",
        "\n",
        "# For crew column - udf for extracting directors' names only from crew json string\n",
        "directors_udf = F.udf(lambda arr: [arr[i+1][7:] for i in range(len(arr))\n",
        " if arr[i] == \" job: Director\"])\n",
        "df = df.withColumn('directors', directors_udf(F.col(\"crew\")))\\\n",
        "  .drop(\"crew\")\n",
        "\n",
        "# Converting arrays strings to arrays of strings\n",
        "column_names = [\"actors\", \"directors\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "print(\"Credits table:\")\n",
        "df.show()\n",
        "credits_df = df\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# Current file: movies.csv\n",
        "movies_file = '/content/drive/MyDrive/Colab Files/DDBMS//movies.csv'\n",
        "df = spark.read.csv(movies_file, header='True', inferSchema='True')\n",
        "\n",
        "# Doing the same process for all columns\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\", \"cities\"]\n",
        "for name in column_names:\n",
        "  temp_name_1 = name + \"1\"\n",
        "  temp_name_2 = name + \"2\"\n",
        "  # Removing irrelevant chars\n",
        "  df = df.select(\"*\", F.translate(F.col(name), \"\\\\{\\\\[\\\\]'\\\\}\", \"\")\\\n",
        "                .alias(temp_name_1))\\\n",
        "  .drop(name)\n",
        "\n",
        "  # Converting arrays strings to arrays of strings\n",
        "  df = df.select(\"*\", F.split(F.col(temp_name_1),\",\").alias(temp_name_2)) \\\n",
        "      .drop(temp_name_1)\n",
        "  df = df.withColumnRenamed(temp_name_2,name)\n",
        "\n",
        "# Finished working on cities column, and seperating production_companies\n",
        "# because it has different structure\n",
        "column_names = [\"genres\", \"production_countries\", \"spoken_languages\"]\n",
        "\n",
        "# For each column - udf for extracting names only from json string\n",
        "name_udf = F.udf(lambda arr: [arr[i][7:] for i in range(len(arr)) if i % 2 == 1])\n",
        "for c in column_names:\n",
        "  c_1 = c + \"1\"\n",
        "  df = df.withColumn(c_1, name_udf(F.col(c)))\\\n",
        "    .drop(c)\n",
        "prod_udf = F.udf(lambda arr: [arr[i][6:] for i in range(len(arr)) if i % 2 == 0])\n",
        "df = df.withColumn(\"production_companies1\", prod_udf(F.col(\"production_companies\")))\\\n",
        "  .drop(\"production_companies\")\n",
        "\n",
        "# Renameing columns names\n",
        "column_names = [\"genres\", \"production_companies\", \"production_countries\", \n",
        "                \"spoken_languages\"]\n",
        "for name in column_names:\n",
        "  current_name = name + \"1\"\n",
        "  df = df.withColumnRenamed(current_name,name)\n",
        "\n",
        "print(\"Movies table:\")\n",
        "df.show()\n",
        "movies_df = df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV8VzIn_FvJ3",
        "outputId": "ec279afc-9d63-4aa7-ba36-ac63d869cb5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries table:\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|user_id|              genres|                lang|              actors|            director|              cities|             country|from_realese_date|  production_company|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "|    981| [Western,  Mystery]|  [English,  Srpski]|                  []|      [Nae Caranfil]|  [Haifa,  Tiberias]|                  []|           [2012]|[Katakuri-ke no K...|\n",
            "|   3775|  [Action,  Western]|           [English]|                  []|                  []|          [Tel Aviv]|                  []|           [2013]|[Clavius Base,  T...|\n",
            "|   4095|             [Crime]|[English,  עִבְרִית]|[Kenneth Alton,  ...|                  []|         [Jerusalem]| [Belgium,  Moldova]|           [1995]|[Peter Carsten Pr...|\n",
            "|   3363|[Animation,  West...|           [English]|                  []|      [Philip Dunne]|             [Haifa]|           [Croatia]|           [2014]|[Centrul de Produ...|\n",
            "|   8982|[Action,  Documen...|           [English]|                  []|                  []|[Tel Aviv,  Jerus...|                  []|           [2018]|[Vortex Words Pic...|\n",
            "|   7603|          [TV Movie]|           [English]|[Tom Hanks,  Stua...|                  []|         [Jerusalem]|  [Jamaica,  Israel]|           [1999]|   [Northern Lights]|\n",
            "|   3112|[Fantasy,  Advent...|           [English]|                  []|                  []|             [Eilat]|[Guatemala,  Kyrg...|           [1996]|[Warner Bros,  Pi...|\n",
            "|   7217|[Drama,  Animatio...|[English,  עִבְרִית]|                  []|                  []|         [Jerusalem]|    [Qatar,  Israel]|           [1999]|             [Chill]|\n",
            "|   9716|   [Crime,  Romance]|           [English]|                  []|                  []|             [Eilat]|[Switzerland,  Mo...|           [2006]|[Monogram Picture...|\n",
            "|   4832|[Drama,  Animatio...|           [English]|                  []|    [Michael Tiddes]|             [Haifa]|                  []|           [2012]|[Joel Productions...|\n",
            "|   8260|            [Family]|           [English]|[\"\"\"Terry OQuinn\"...|                  []|          [Tiberias]| [Namibia,  Morocco]|           [1998]|[TROS Bridge Rights]|\n",
            "|   2772|   [Action,  Family]|           [English]|[Harry Carey,  Jr...|                  []|          [Tel Aviv]|                  []|           [2017]|[MGM-Pathé Commun...|\n",
            "|   8971|[Adventure,  Scie...|           [English]|                  []|                  []|             [Eilat]|  [Congo,  Ethiopia]|           [2004]|[Walt Disney Pict...|\n",
            "|  10496| [Drama,  Animation]|           [English]|[Osamu Hosoi,  Eu...|[Julia Sweeney,  ...|             [Haifa]|                  []|           [2016]|[RTV Slovenija,  ...|\n",
            "|   9658|[Drama,  Adventur...|           [English]|      [Otto Klopsch]|       [So Yong Kim]|             [Haifa]|                  []|           [2018]|[Rational Packagi...|\n",
            "|  10114|[Horror,  Adventure]| [English,  ภาษาไทย]|                  []|                  []|             [Eilat]|[Netherlands,  Ka...|           [2016]|[Walt Disney Pict...|\n",
            "|   2727|[Drama,  Adventur...|   [English,  ?????]|[Bernadette Leonard]|[Philippe Le Guay...|             [Haifa]|                  []|           [2018]|[HE-Filmproduktio...|\n",
            "|   1889|[Drama,  Horror, ...|           [English]|    [Hassan Majooni]|                  []|             [Haifa]|                  []|           [2016]|[\"\"\"Thats Nice Fi...|\n",
            "|   8235|    [Drama,  Action]|           [English]|        [Gil Herman]|      [Mariano Cohn]|             [Haifa]|                  []|           [2012]|[\"\"\"Centre Nation...|\n",
            "|   6345|[Animation,  Adve...|           [English]|                  []|                  []|             [Eilat]|[South Korea,  Mo...|           [2012]|[Pixar Animation ...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Credits table:\n",
            "+-----+--------------------+--------------------+\n",
            "|   id|              actors|           directors|\n",
            "+-----+--------------------+--------------------+\n",
            "|  862|[Tom Hanks,  Tim ...|     [John Lasseter]|\n",
            "| 8844|[Robin Williams, ...|      [Joe Johnston]|\n",
            "|15602|[Walter Matthau, ...|     [Howard Deutch]|\n",
            "|31357|[Whitney Houston,...|   [Forest Whitaker]|\n",
            "|11862|[Steve Martin,  D...|     [Charles Shyer]|\n",
            "|  949|[Al Pacino,  Robe...|      [Michael Mann]|\n",
            "|11860|[Harrison Ford,  ...|    [Sydney Pollack]|\n",
            "|45325|[Jonathan Taylor ...|      [Peter Hewitt]|\n",
            "| 9091|[Jean-Claude Van ...|       [Peter Hyams]|\n",
            "|  710|[Pierce Brosnan, ...|   [Martin Campbell]|\n",
            "| 9087|[Michael Douglas,...|        [Rob Reiner]|\n",
            "|12110|[Leslie Nielsen, ...|        [Mel Brooks]|\n",
            "|21032|[Kevin Bacon,  Bo...|       [Simon Wells]|\n",
            "|10858|[Anthony Hopkins,...|      [Oliver Stone]|\n",
            "| 1408|[Geena Davis,  Ma...|      [Renny Harlin]|\n",
            "|  524|[Robert De Niro, ...|   [Martin Scorsese]|\n",
            "| 4584|[Kate Winslet,  E...|           [Ang Lee]|\n",
            "|    5|[Tim Roth,  Anton...|[Allison Anders, ...|\n",
            "| 9273|[Jim Carrey,  Ian...|    [Steve Oedekerk]|\n",
            "|11517|[Wesley Snipes,  ...|      [Joseph Ruben]|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Movies table:\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|movie_id|            overview|        release_date|             revenue|             tagline|               title|              cities|              genres|production_countries|    spoken_languages|production_companies|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     862|Led by Woody, And...|          30/10/1995|           373554033|                null|           Toy Story|[Eilat,  Tel Aviv...|[Animation, Comed...|[United States of...|           [English]|[Pixar Animation ...|\n",
            "|    8844|When siblings Jud...|          15/12/1995|           262797249|Roll the dice and...|             Jumanji|[Jerusalem,  Tibe...|[Adventure, Fanta...|[United States of...|[English, FranÃ§ais]|[TriStar Pictures...|\n",
            "|   15602|A family wedding ...|          22/12/1995|                   0|Still Yelling. St...|    Grumpier Old Men|[Eilat,  Haifa,  ...|   [Romance, Comedy]|[United States of...|           [English]|[Warner Bros.,  L...|\n",
            "|   31357|\"Cheated on, mist...| determined to fi...|[{'name': 'Twenti...|          22/12/1995|            81452156|[iso_639_1: en,  ...|[Comedy, Drama, R...|                  []|[United States of...|                 [e]|\n",
            "|   11862|Just when George ...|          10/02/1995|            76578911|Just When His Wor...|Father of the Bri...|[Haifa,  Jerusale...|            [Comedy]|[United States of...|           [English]|[Sandollar Produc...|\n",
            "|     949|Obsessive master ...|          15/12/1995|           187436818|A Los Angeles Cri...|                Heat|[Tiberias,  Jerus...|[Action, Crime, D...|[United States of...| [English, EspaÃ±ol]|[Regency Enterpri...|\n",
            "|   11860|An ugly duckling ...|          15/12/1995|                   0|You are cordially...|             Sabrina|[Eilat,  Jerusale...|   [Comedy, Romance]|[Germany, United ...|[FranÃ§ais, English]|[Paramount Pictur...|\n",
            "|   45325|A mischievous you...|          22/12/1995|                   0|The Original Bad ...|        Tom and Huck|[Haifa,  Jerusale...|[Action, Adventur...|[United States of...|  [English, Deutsch]|[Walt Disney Pict...|\n",
            "|    9091|International act...|          22/12/1995|            64350171|Terror goes into ...|        Sudden Death|[Tiberias,  Haifa...|[Action, Adventur...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|     710|James Bond must u...|          16/11/1995|           352194034|No limits. No fea...|           GoldenEye|[Eilat,  Tiberias...|[Adventure, Actio...|[United Kingdom, ...|[English, PÑÑÑ...|[United Artists, ...|\n",
            "|    9087|Widowed U.S. pres...|          17/11/1995|           107879496|Why can't the mos...|The American Pres...|[Haifa,  Tel Aviv...|[Comedy, Drama, R...|[United States of...|           [English]|[Columbia Picture...|\n",
            "|   12110|When a lawyer sho...|          22/12/1995|                   0|                null|Dracula: Dead and...|[Tiberias,  Jerus...|    [Comedy, Horror]|[France, United S...|  [English, Deutsch]|[Columbia Picture...|\n",
            "|   21032|An outcast half-w...|          22/12/1995|            11348324|Part Dog. Part Wo...|               Balto|[Jerusalem,  Haif...|[Family, Animatio...|[United States of...|           [English]|[Universal Pictur...|\n",
            "|   10858|An all-star cast ...|          22/12/1995|            13681765|Triumphant in Vic...|               Nixon|[Eilat,  Haifa,  ...|    [History, Drama]|[United States of...|           [English]|[Hollywood Pictur...|\n",
            "|    1408|Morgan Adams and ...|          22/12/1995|            10017322|The Course Has Be...|    Cutthroat Island|[Tiberias,  Eilat...| [Action, Adventure]|[France, Germany,...|    [English, Latin]|[Le Studio Canal+...|\n",
            "|     524|The life of the g...|          22/11/1995|           116112375|No one stays at t...|              Casino|[Tel Aviv,  Eilat...|      [Drama, Crime]|[France, United S...|           [English]|[Universal Pictur...|\n",
            "|    4584|Rich Mr. Dashwood...|          13/12/1995|           135000000|Lose your heart a...|Sense and Sensibi...|[Haifa,  Eilat,  ...|    [Drama, Romance]|[United Kingdom, ...|           [English]|[Columbia Picture...|\n",
            "|       5|It's Ted the Bell...|          09/12/1995|             4300000|Twelve outrageous...|          Four Rooms|[Haifa,  Eilat,  ...|     [Crime, Comedy]|[United States of...|           [English]|[Miramax Films,  ...|\n",
            "|    9273|Summoned from an ...|          10/11/1995|           212385533|New animals. New ...|Ace Ventura: When...|[Tiberias,  Tel A...|[Crime, Comedy, A...|[United States of...|           [English]|[O Entertainment,...|\n",
            "|   11517|A vengeful New Yo...|          21/11/1995|            35431113|Get on, or GET OU...|         Money Train|[Eilat,  Jerusale...|[Action, Comedy, ...|[United States of...|           [English]| [Columbia Pictures]|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%\n",
        "# Section 2 - Data Analysis\n",
        "\n",
        "# Insight 1: Tel Aviv is the most queried city with 44721 lookups, Jerusalem is right after with 34561\n",
        "# and then Haifa, Tiberias and Eilat with 22712, 9594 and 17348 lookups respectively\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  for city in row.cities:\n",
        "    counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"Insight 1: Tel Aviv is the most queried city with 44721 lookups, Jerusalem is right after with 34561, and then Haifa, Tiberias and Eilat with 22712, 9594 and 17348 lookups respectively\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "# Insight 2: Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "            \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "\n",
        "for row in queries_itr:\n",
        "  if \" עִבְרִית\" in row.lang:\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                  \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                  \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                  \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                  \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"Insight 2: Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "\n",
        "# Insight 3: Jerusalemites care about the playing actors, Haifa people care \n",
        "# about directors, and Eilaties alaways specify countries in their queries.\n",
        "print(\"Insight 3: Jerusalemites care about the playing actors, Haifa people care about directors, and Eilaties alaways specify countries in their queries.\")\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.actors[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print()\n",
        "print(\"actors empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.director[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"director empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {\"Tel Aviv\": 0, \"Jerusalem\": 0, \"Haifa\": 0, \"Tiberias\": 0, \"Eilat\": 0,\n",
        "          \" Tel Aviv\": 0, \" Jerusalem\": 0, \" Haifa\": 0, \" Tiberias\": 0, \" Eilat\": 0}\n",
        "for row in queries_itr:\n",
        "  if row.country[0] == \"\":\n",
        "    for city in row.cities:\n",
        "      counters[city] += 1\n",
        "\n",
        "counters_final = {\"Tel Aviv\": counters[\"Tel Aviv\"] + counters[\" Tel Aviv\"],\n",
        "                \"Jerusalem\": counters[\"Jerusalem\"] + counters[\" Jerusalem\"],\n",
        "                \"Haifa\": counters[\"Haifa\"] + counters[\" Haifa\"],\n",
        "                \"Tiberias\": counters[\"Tiberias\"] + counters[\" Tiberias\"],\n",
        "                \"Eilat\": counters[\"Eilat\"] + counters[\" Eilat\"]}\n",
        "\n",
        "print(\"country empty by city:\")\n",
        "print(counters_final)\n",
        "print()\n",
        "\n",
        "# Insight 4: people who look for movies in Eilat, never look for movies in over places in the same query\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "city_lookup_dict = {}\n",
        "for row in queries_itr:\n",
        "  key = \" \".join(str(x) for x in row.cities)\n",
        "  if key not in city_lookup_dict.keys():\n",
        "    city_lookup_dict[key] = 1\n",
        "  else:\n",
        "    city_lookup_dict[key] += 1\n",
        "print(\"Insight 4: people who look for movies in Eilat, never look for movies in over places in the same query\")\n",
        "print(\"Lookups for cinemas in different cities counts\")\n",
        "print(city_lookup_dict)\n",
        "print()\n",
        "\n",
        "# Insight 5: the number of tickets in reservations are more or less in the same amount and from the same distribution\n",
        "print(\"Insight 5: the number of tickets in reservations are more or less in the same amount and from the same distribution\")\n",
        "import pandas as pd\n",
        "tickets_by_city = [[\"Tel Aviv\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [\"Jerusalem\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                   [\"Haifa\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [\"Tiberias\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "                   [\"Eilat\", 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
        "tickets_by_city = pd.DataFrame(tickets_by_city, columns=[\"City\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"])\n",
        "tickets_by_city.set_index(\"City\", inplace=True)\n",
        "\n",
        "tickets_df = spark.read.csv('/content/drive/MyDrive/Colab Files/DDBMS//tickets.csv', header='True', inferSchema='True')\n",
        "tickets_itr = tickets_df.rdd.toLocalIterator()\n",
        "for row in tickets_itr:\n",
        "  tickets_by_city.at[row.city, str(row.number_of_tickets)] += 1\n",
        "\n",
        "print(\"Number of tickets per reservation count by city\")\n",
        "print(tickets_by_city)\n",
        "print()\n",
        "ax = tickets_by_city.plot.bar(rot=0)\n",
        "ax.plot()\n",
        "#%% md\n",
        "\n",
        "# Insight 6: Approximately 95% of the users looked for movies in their home towns\n",
        "print(\"Insight 6: Approximately 95% of the users looked for movies in their home towns\")\n",
        "users_df = spark.read.csv('/content/drive/MyDrive/Colab Files/DDBMS//users.csv', header='True', inferSchema='True')\n",
        "unit = users_df.join(queries_df, on=users_df.user_id == queries_df.user_id)\n",
        "unit_itr = unit.rdd.toLocalIterator()\n",
        "cnt = 0\n",
        "for row in unit_itr:\n",
        "  loc = row.user_location\n",
        "  loc_ = \" \" + row.user_location\n",
        "  if loc in row.cities or loc_ in row.cities:\n",
        "    cnt += 1\n",
        "\n",
        "print(cnt)\n",
        "\n",
        "# Insight 7: Most genres are queried in the same propotion, beside a few of them,\n",
        "# which are significantly more popular\n",
        "print(\"Insight 7: Most genres are queried in the same propotion, beside a few of them,\\\n",
        " which are significantly more popular\")\n",
        "all_genres = set()\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "for row in queries_itr:\n",
        "  for g in row.genres:\n",
        "    if g != \"\" and not( \" \" + g in all_genres):\n",
        "      all_genres.add(g)\n",
        "\n",
        "all_genres_2 = set(all_genres)\n",
        "for strr in all_genres:\n",
        "  if strr[0] == \" \":\n",
        "    all_genres_2.add(strr[1:])\n",
        "    all_genres_2.remove(strr)\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {}\n",
        "for g in all_genres_2:\n",
        "  counters[g] = 0\n",
        "\n",
        "for row in queries_itr:\n",
        "  for g in row.genres:\n",
        "    if g != \"\":\n",
        "      counters[g.lstrip()] += 1\n",
        "\n",
        "print(counters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "u9rb0gnNbPnc",
        "outputId": "14dafeea-37f0-4f9d-c0a9-b2d2f1f78289"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insight 1: Tel Aviv is the most queried city with 44721 lookups, Jerusalem is right after with 34561, and then Haifa, Tiberias and Eilat with 22712, 9594 and 17348 lookups respectively\n",
            "{'Tel Aviv': 44721, 'Jerusalem': 34561, 'Haifa': 22712, 'Tiberias': 9594, 'Eilat': 17348}\n",
            "\n",
            "Insight 2: Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew:\n",
            "{'Tel Aviv': 15958, 'Jerusalem': 26274, 'Haifa': 104, 'Tiberias': 56, 'Eilat': 67}\n",
            "\n",
            "Insight 3: Jerusalemites care about the playing actors, Haifa people care about directors, and Eilaties alaways specify countries in their queries.\n",
            "\n",
            "actors empty by city:\n",
            "{'Tel Aviv': 13884, 'Jerusalem': 3322, 'Haifa': 11394, 'Tiberias': 4815, 'Eilat': 17348}\n",
            "\n",
            "director empty by city:\n",
            "{'Tel Aviv': 42147, 'Jerusalem': 33482, 'Haifa': 2784, 'Tiberias': 5477, 'Eilat': 16816}\n",
            "\n",
            "country empty by city:\n",
            "{'Tel Aviv': 25335, 'Jerusalem': 3584, 'Haifa': 20992, 'Tiberias': 4149, 'Eilat': 0}\n",
            "\n",
            "Insight 4: people who look for movies in Eilat, never look for movies in over places in the same query\n",
            "Lookups for cinemas in different cities counts\n",
            "{'Haifa  Tiberias': 4072, 'Tel Aviv': 21151, 'Jerusalem': 12285, 'Haifa': 17346, 'Tel Aviv  Jerusalem': 22276, 'Eilat': 17348, 'Tiberias': 4228, 'Haifa  Tiberias  Tel Aviv': 1294}\n",
            "\n",
            "Insight 5: the number of tickets in reservations are more or less in the same amount and from the same distribution\n",
            "Number of tickets per reservation count by city\n",
            "               1      2      3     4     5    6   7   8  9  10\n",
            "City                                                          \n",
            "Tel Aviv   43383  27412  13328  5137  1507  403  80  11  1   0\n",
            "Jerusalem  42000  26774  12997  4960  1480  314  71  18  2   1\n",
            "Haifa      43923  28146  13510  4974  1497  388  94  13  0   1\n",
            "Tiberias   42879  27482  13217  4929  1509  370  85   8  1   0\n",
            "Eilat      45165  28843  14167  5349  1628  375  92  14  2   0\n",
            "\n",
            "Insight 6: Approximately 95% of the users looked for movies in their home towns\n",
            "94712\n",
            "Insight 7: Most genres are queried in the same propotion, beside a few of them, which are significantly more popular\n",
            "{'Music': 7741, 'Action': 26630, 'TV Movie': 7641, 'Science Fiction': 7763, 'Fantasy': 7689, 'Drama': 24542, 'Adventure': 7692, 'Crime': 7755, 'Foreign': 7751, 'Family': 10227, 'Romance': 7654, 'Thriller': 7618, 'Comedy': 7684, 'Documentary': 10116, 'Western': 7608, 'Mystery': 7809, 'Animation': 7720, 'Horror': 7576, 'War': 7822, 'History': 7661}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insight 7: Most genres are queried in the same propotion, beside a few of them,\n",
        "# which are significantly more popular\n",
        "print(\"Insight 7: Most genres are queried in the same propotion, beside a few of them,\\\n",
        " which are significantly more popular\")\n",
        "all_genres = set()\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "for row in queries_itr:\n",
        "  for g in row.genres:\n",
        "    if g != \"\" and not( \" \" + g in all_genres):\n",
        "      all_genres.add(g)\n",
        "\n",
        "all_genres_2 = set(all_genres)\n",
        "for strr in all_genres:\n",
        "  if strr[0] == \" \":\n",
        "    all_genres_2.add(strr[1:])\n",
        "    all_genres_2.remove(strr)\n",
        "\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "counters = {}\n",
        "for g in all_genres_2:\n",
        "  counters[g] = 0\n",
        "\n",
        "for row in queries_itr:\n",
        "  for g in row.genres:\n",
        "    if g != \"\":\n",
        "      counters[g.lstrip()] += 1\n",
        "\n",
        "print(counters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpBYiB8K6fgD",
        "outputId": "97773673-35e7-4704-b465-16640e1bfab4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insight 7: Most genres are queried in the same propotion, beside a few of them, which are significantly more popular\n",
            "{'Music': 7741, 'Action': 26630, 'TV Movie': 7641, 'Science Fiction': 7763, 'Fantasy': 7689, 'Drama': 24542, 'Adventure': 7692, 'Crime': 7755, 'Foreign': 7751, 'Family': 10227, 'Romance': 7654, 'Thriller': 7618, 'Comedy': 7684, 'Documentary': 10116, 'Western': 7608, 'Mystery': 7809, 'Animation': 7720, 'Horror': 7576, 'War': 7822, 'History': 7661}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the project we have chosen to focus on finding insights mainly from the \"queries\" table as well as from the \"tickets\" table, and in particular those that will help us in the horizontal fregmentation, since the vertical fregmenataion is more easy to implement by code and the horizontal is more dependent on our previous knowladge about the database.\n",
        "\n",
        "Since the general task in this part of the project is to divide the database between sites that are geographically close to the cities of Haifa, Tiberias, Tel Aviv, Jerusalem and Eilat, we found it appropriate to focus on the differences embodied in the database between the cities, hoping that if we find significant differences between cities, we would be able to generalize them for certain rows / columns in the database.\n",
        "\n",
        "Indeed, we have found some interesting insights, as one can see from the above code output:\n",
        "\n",
        "1. Jerusalemites and Tel-Avivians are almost the only ones to search for movies in Hebrew.\n",
        "2. Jerusalemites care much about the playing actors, Haifa people care much about directors, and Eilaties alaways specify countries in their queries.\n",
        "3. People who look for movies in Eilat, never look for movies in over places in the same query.\n",
        "4. The numbers of tickets in reservations are more or less in the same amount and from the same distribution."
      ],
      "metadata": {
        "id": "GOtubTXOasx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PboWTSvtakuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3 - Design\n",
        "# here we will work on vertical fragmantations only.\n",
        "# for horizontal fragmantation look section's pdf.\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# statistics about the nature of qureries\n",
        "# from here and on, we will consider these as generic queries with the calculated query-access\n",
        "def row_counter(my_array):\n",
        "    # count identical rows in matrix\n",
        "    list_of_tups = [tuple(ele) for ele in my_array]\n",
        "    return Counter(list_of_tups)\n",
        "\n",
        "# build use matrix for queries and shrink it\n",
        "shape = (queries_df.count(), len(queries_df.columns))\n",
        "queries_use = np.zeros(shape)\n",
        "queries_itr = queries_df.rdd.toLocalIterator()\n",
        "for i, row in enumerate(queries_itr):\n",
        "  for j, col in enumerate(queries_df.columns):\n",
        "    if type(row[col]) != list:\n",
        "      queries_use[i, j] = 1\n",
        "    else:\n",
        "      queries_use[i, j] = 0 if row[col][0] == \"\" else 1\n",
        "\n",
        "access = row_counter(queries_use)\n",
        "\n",
        "for key, value in access.items():\n",
        "    print(f\"{key} : {value}\")\n",
        "\n",
        "# user_id | genres | lang | actors | director | cities | country | from_realese_date | production_company"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWzVvDizvcRY",
        "outputId": "558b06a4-b556-43ec-c4af-cf8993806cf2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0) : 10046\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0) : 12416\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 31305\n",
            "(1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 965\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 21205\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0) : 12620\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0) : 9983\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 1308\n",
            "(1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 64\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0) : 3\n",
            "(1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 3\n",
            "(1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0) : 70\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0) : 5\n",
            "(1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0) : 4\n",
            "(1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0) : 1\n",
            "(1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0) : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_queries = 8\n",
        "n_attributes = 2\n",
        "#attribute usage matrix on movies\n",
        "\n",
        "# actors | director\n",
        "aum = [ [0.0, 1.0],\n",
        "        [0.0, 0.0],\n",
        "        [1.0, 0.0],\n",
        "        [0.0, 1.0],\n",
        "        [0.0, 0.0],\n",
        "        [1.0, 0.0],\n",
        "        [1.0, 1.0],\n",
        "        [1.0, 1.0]]\n",
        "\n",
        "#number of sites\n",
        "n_sites = 5\n",
        "\n",
        "#access matrix\n",
        "acc = [[10046/200000, 10046/200000,10046/200000,10046/200000,10046/200000, 10046/200000],\n",
        "       [12412/600000, 12416/200000,12416/200000,12416/200000,12416/200000, 12416/200000],\n",
        "       [31305/200000, 31305/200000,31305/200000,31305/200000,31305/200000, 31305/200000],\n",
        "       [965/200000, 965/200000,965/200000,965/200000,965/200000, 965/200000],\n",
        "       [21205/200000, 21205/200000,21205/200000,21205/200000,21205/200000, 21205/200000],\n",
        "       [12620/200000, 12620/200000,12620/200000,12620/200000,12620/200000, 12620/200000],\n",
        "       [9983/200000, 9983/200000,9983/200000,9983/200000,9983/200000, 9983/200000],\n",
        "       [1308/200000, 1308/200000,1308/200000,1308/200000,1308/200000, 1308/200000],\n",
        "       ]"
      ],
      "metadata": {
        "id": "TivK_FknyxOK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prefix sum for each query\n",
        "pre = [0 for i in range(n_queries)]\n",
        "for i in range(n_queries):\n",
        "    for j in range(n_sites):\n",
        "        pre[i] = pre[i]+acc[i][j]\n",
        "\n",
        "#attribute affinity matrix\n",
        "aam = [[0 for i in range(n_attributes)] for j in range(n_attributes)]\n",
        "\n",
        "#calculation of the aam\n",
        "for i in range(n_attributes):\n",
        "    for j in range(n_attributes):\n",
        "         for q in range(n_queries):\n",
        "            if aum[q][i]==1 and aum[q][j]==1:\n",
        "                aam[i][j] = aam[i][j]+pre[q]\n",
        "          \n",
        "print(\"Attribute affinity matrix\")\n",
        "for i in range(n_attributes):\n",
        "    print(aam[i])\n",
        "print(\"Access Site Sums\")\n",
        "print(pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEGe-IBItOUZ",
        "outputId": "f05d6d00-25d9-4d83-c9c3-2d768f803ecc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute affinity matrix\n",
            "[1.3804, 0.282275]\n",
            "[0.282275, 0.55755]\n",
            "Access Site Sums\n",
            "[0.25115, 0.26900666666666667, 0.782625, 0.024125, 0.530125, 0.3155, 0.249575, 0.0327]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bond(Ax,Ay):\n",
        "    if Ax==-1 or Ay==-1:\n",
        "        return 0\n",
        "    ans = 0\n",
        "    for i in range(n_attributes):\n",
        "        ans = ans + (aam[i][Ax]*aam[i][Ay])\n",
        "    return ans\n",
        "\n",
        "def cont(Ai,Ak,Aj):\n",
        "    print(\"bond \",Ai, \"bond\", Ak, \" = \", bond(Ai,Ak))\n",
        "    print(\"bond \",Ak, \"bond\", Aj, \" = \", bond(Ak,Aj))\n",
        "    print(\"bond \",Ai, \"bond\", Aj, \" = \", bond(Ai,Aj))\n",
        "    return 2*bond(Ai,Ak) + 2*bond(Ak,Aj) - 2*bond(Ai,Aj)"
      ],
      "metadata": {
        "id": "I3Ex1gb_0mKe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bond energy algorithm\n",
        "def BEA():\n",
        "    ca = []\n",
        "    ca.append(0)\n",
        "    ca.append(1)\n",
        "    index  = 2\n",
        "    while index < n_attributes:\n",
        "        maxi = -1 \n",
        "        maxc = -100000\n",
        "        for i in range(1,index):\n",
        "                con = cont(ca[i-1],index,ca[i])\n",
        "                print(\"Index \", i+1, \" \", \"cont \", ca[i],index+1,ca[i]+1, con)\n",
        "                if con > maxc:\n",
        "                    maxi = i\n",
        "                    maxc = con\n",
        "        #boundary left\n",
        "        con = cont(-1,index,ca[0])\n",
        "        print(\"Index \", i+1, \" \", \"cont \", 1,index+1,ca[0]+1, con)\n",
        "        if con > maxc:\n",
        "            maxi = 0\n",
        "            maxc = con\n",
        "        #boundary right\n",
        "        con = cont(ca[index-1],index,-1)\n",
        "        print(\"Index \", i+1, \" \", \"cont \", ca[index-1]+1,index+1,index+2, con)\n",
        "        if con > maxc:\n",
        "            maxi = index\n",
        "        if maxi==index:\n",
        "            ca.append(index)    \n",
        "        else:\n",
        "            ca.append(0)\n",
        "            for j in range(index,maxi,-1):\n",
        "                ca[j]=ca[j-1]\n",
        "            ca[maxi] = index\n",
        "        print(ca)\n",
        "        index = index + 1\n",
        "    print(\"FINAL Clustered Affinity Matrix\")\n",
        "    print(ca)\n",
        "    return ca"
      ],
      "metadata": {
        "id": "FoWDIU8P0uHo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CA = BEA()\n",
        "ca = [[0 for i in range(n_attributes)] for j in range(n_attributes)]\n",
        "for i in range(n_attributes):\n",
        "    for j in range(n_attributes):\n",
        "        ca[i][j] = aam[CA[i]][CA[j]]\n",
        "\n",
        "print(ca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "789Jdi8b0x3t",
        "outputId": "36f630b6-0d50-406e-eec6-992136c7042a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL Clustered Affinity Matrix\n",
            "[0, 1]\n",
            "[[1.3804, 0.282275], [0.282275, 0.55755]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shift_row_aum(mat):\n",
        "    row_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        row_first.append(mat[0][i])\n",
        "    for i in range(1,n_queries):\n",
        "        for j in range(n_attributes):\n",
        "            mat[i-1][j]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[n_queries-1][i]=row_first[i]\n",
        "   # print(row_first)\n",
        "    return mat\n",
        "   \n",
        "def shift_column_aum(mat):\n",
        "    col_first=[]\n",
        "    for i in range(n_queries):\n",
        "        col_first.append(mat[i][0])\n",
        "    for i in range(n_queries):\n",
        "        for j in range(1,n_attributes):\n",
        "            mat[i][j-1]=mat[i][j]\n",
        "    for i in range(n_queries):\n",
        "        mat[i][n_attributes-1]=col_first[i]\n",
        "    return mat"
      ],
      "metadata": {
        "id": "oeHZMlKk1KIk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shift_row_ca(mat):\n",
        "    row_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        row_first.append(mat[0][i])\n",
        "    for i in range(1,n_attributes):\n",
        "        for j in range(n_attributes):\n",
        "            mat[i-1][j]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[n_attributes-1][i]=row_first[i]\n",
        "   # print(row_first)\n",
        "    return mat\n",
        "   \n",
        "def shift_column_ca(mat):\n",
        "    col_first=[]\n",
        "    for i in range(n_attributes):\n",
        "        col_first.append(mat[i][0])\n",
        "    for i in range(n_attributes):\n",
        "        for j in range(1,n_attributes):\n",
        "            mat[i][j-1]=mat[i][j]\n",
        "    for i in range(n_attributes):\n",
        "        mat[i][n_attributes-1]=col_first[i]\n",
        "    return mat"
      ],
      "metadata": {
        "id": "-E0ehrb-1lpG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Partioning\n",
        "# this block computes access-query\n",
        "# output - list of list, in each list i we see the attributes accessed by query i\n",
        "start=n_attributes-2\n",
        "aum = [ [0.0, 1.0],\n",
        "        [0.0, 0.0],\n",
        "        [1.0, 0.0],\n",
        "        [0.0, 1.0],\n",
        "        [0.0, 0.0],\n",
        "        [1.0, 0.0],\n",
        "        [1.0, 1.0],\n",
        "        [1.0, 1.0]]\n",
        "AQ=[]\n",
        "for i in range(n_queries):\n",
        "    row=[]\n",
        "    for j in range(n_attributes):\n",
        "        if aum[i][j]==1:\n",
        "            row.append(j)\n",
        "    AQ.append(row)\n",
        "\n",
        "print(AQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLWfL6jX1n_e",
        "outputId": "699b66f1-11d8-44d8-c635-a278b8494765"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1], [], [0], [1], [], [0], [0, 1], [0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computing TQ, BQ, OQ and costs for each permutation\n",
        "\n",
        "# all permutations of attributes\n",
        "shifts_list = [CA]\n",
        "shifted = list(CA)\n",
        "for i in range(len(CA)-1):\n",
        "  shifted.append(shifted[0])\n",
        "  shifted.pop(0)\n",
        "  shifts_list.append(list(shifted))\n",
        "\n",
        "# compute best vertical fragmantation\n",
        "max_res = -np.inf\n",
        "for shift in shifts_list:\n",
        "  for seperator in range(1, len(shift)):\n",
        "    TQ=[]\n",
        "    BQ=[]\n",
        "    OQ=[]\n",
        "    until_seperator = shift[:seperator]\n",
        "    from_seperator = shift[seperator:]\n",
        "    # paritioned queries to TQ/BQ/OQ \n",
        "    for i in range(len(AQ)):\n",
        "      if set(AQ[i]).issubset(set(until_seperator)):\n",
        "        TQ.append(i)\n",
        "      elif set(AQ[i]).issubset(set(from_seperator)):\n",
        "        BQ.append(i)\n",
        "      elif set(AQ[i]).issubset(set(shift)):\n",
        "        OQ.append(i)\n",
        "    CTQ = np.array([acc[i] for i in TQ]).sum(axis=0).sum()\n",
        "    CBQ = np.array([acc[i] for i in BQ]).sum(axis=0).sum()\n",
        "    COQ = np.array([acc[i] for i in OQ]).sum(axis=0).sum()\n",
        "    res = CTQ*CBQ - COQ**2\n",
        "    if res > max_res:\n",
        "      max_res = res\n",
        "      res_shift = shift\n",
        "      res_seperator = [until_seperator, from_seperator]\n",
        "\n",
        "print(f\"vertical fragmantation: {res_seperator}\")\n",
        "print(f\"max res = {max_res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh1uIR832OKM",
        "outputId": "38a74a8d-df82-4ac0-ed2d-713c88c4c688"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vertical fragmantation: [[1], [0]]\n",
            "max res = 1.5951304620999998\n"
          ]
        }
      ]
    }
  ]
}